{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from transformer import Models\n",
    "from transformer import Beam\n",
    "from transformer import Translator\n",
    "from transformer.Optim import ScheduledOptim\n",
    "\n",
    "from tools import CharacterTable\n",
    "from translator import SignalTranslator\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighting the loss in the middle of the sequence\n",
    "# Different lengths for protein in training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants. Don't change these. \n",
    "pad = 0\n",
    "stop = 2\n",
    "start = 1\n",
    "max_in = 107\n",
    "max_out = 72\n",
    "n_chars = 27\n",
    "\n",
    "# Hyperparameters. Do change these\n",
    "d_model = 550\n",
    "batch_size = 64\n",
    "batches = 500 # batches / epoch\n",
    "n_warmup_steps = batches * 25\n",
    "n_layers = 6\n",
    "n_head = 5\n",
    "dropout = 0.1\n",
    "d_k = 64\n",
    "epochs = 5\n",
    "lr_max = 1e-4\n",
    "decay_power = -0.03\n",
    "\n",
    "# Name for the model checkpoints\n",
    "# Change this, probably to reflect the hyperparameters chosen above\n",
    "hypers = [d_model, n_warmup_steps, batch_size, n_layers, n_head, dropout, d_k, epochs, lr_max, decay_power]\n",
    "chkpt_name = '_'.join([str(h) for h in hypers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'550_12500_64_6_5_0.1_64_5_0.0001_-0.03'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt = argparse.Namespace()\n",
    "model_opt.src_vocab_size = n_chars\n",
    "model_opt.tgt_vocab_size = n_chars\n",
    "model_opt.max_token_seq_len = max_in\n",
    "model_opt.proj_share_weight = True\n",
    "model_opt.embs_share_weight = True\n",
    "model_opt.d_k = d_k\n",
    "model_opt.d_v = d_k\n",
    "model_opt.d_model = d_model\n",
    "model_opt.d_word_vec = d_model\n",
    "model_opt.d_inner_hid = 2 * d_model\n",
    "model_opt.n_layers = n_layers\n",
    "model_opt.n_head = n_head\n",
    "model_opt.dropout = dropout\n",
    "\n",
    "##############################\n",
    "# Change this to use the GPU #\n",
    "model_opt.cuda = True        #\n",
    "##############################\n",
    "\n",
    "optim_opt = argparse.Namespace()\n",
    "optim_opt.n_warmup_steps = n_warmup_steps\n",
    "optim_opt.optim = optim.Adam\n",
    "optim_opt.lr_max = lr_max\n",
    "optim_opt.decay_power = decay_power\n",
    "optim_opt.d_model = None\n",
    "\n",
    "trans_opt = argparse.Namespace()\n",
    "trans_opt.beam_size = 1\n",
    "trans_opt.n_best = 1\n",
    "trans_opt.max_trans_length = max_out\n",
    "\n",
    "with open('../outputs/ctable_token.pkl', 'rb') as f:\n",
    "    ctable = pickle.load(f)\n",
    "    \n",
    "trans_opt.ctable = ctable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiated Transformer with 27403200 parameters.\n"
     ]
    }
   ],
   "source": [
    "clf = SignalTranslator(model_opt, optim_opt, trans_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loading the model\n",
    "#chkpt = \"../outputs/models/\" + chkpt_name + \".chkpt\"\n",
    "#clf = SignalTranslator.load_model(chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = np.arange(epochs * batches)\n",
    "lrs = clf.optimizer.get_learning_rate(steps)\n",
    "_ = plt.plot(steps, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Training batch 1\tloss: 14.2777\tacc: 0.0252\r",
      "Training batch 2\tloss: 19.7413\tacc: 0.0125\r",
      "Training batch 3\tloss: 21.4868\tacc: 0.0082\r",
      "Training batch 4\tloss: 22.3160\tacc: 0.0062\r",
      "Training batch 5\tloss: 22.8202\tacc: 0.0050\r",
      "Training batch 6\tloss: 23.1691\tacc: 0.0042\r",
      "Training batch 7\tloss: 23.4163\tacc: 0.0035\r",
      "Training batch 8\tloss: 23.5948\tacc: 0.0031\r",
      "Training batch 9\tloss: 23.7345\tacc: 0.0028\r",
      "Training batch 10\tloss: 23.8536\tacc: 0.0025\r",
      "Training batch 11\tloss: 23.9542\tacc: 0.0023\r",
      "Training batch 12\tloss: 24.0273\tacc: 0.0021\r",
      "Training batch 13\tloss: 24.0925\tacc: 0.0019\r",
      "Training batch 14\tloss: 24.1432\tacc: 0.0018\r",
      "Training batch 15\tloss: 24.1951\tacc: 0.0017\r",
      "Training batch 16\tloss: 24.2401\tacc: 0.0016\r",
      "Training batch 17\tloss: 24.2719\tacc: 0.0015\r",
      "Training batch 18\tloss: 24.3010\tacc: 0.0014\r",
      "Training batch 19\tloss: 24.3366\tacc: 0.0013\r",
      "Training batch 20\tloss: 24.3620\tacc: 0.0013\r",
      "Training batch 21\tloss: 24.3896\tacc: 0.0012\r",
      "Training batch 22\tloss: 24.4096\tacc: 0.0011\r",
      "Training batch 23\tloss: 24.4261\tacc: 0.0011\r",
      "Training batch 24\tloss: 24.4404\tacc: 0.0010\r",
      "Training batch 25\tloss: 24.4517\tacc: 0.0010\r",
      "Training batch 26\tloss: 24.4609\tacc: 0.0010\r",
      "Training batch 27\tloss: 24.4752\tacc: 0.0009\r",
      "Training batch 28\tloss: 24.4867\tacc: 0.0009\r",
      "Training batch 29\tloss: 24.4934\tacc: 0.0009\r",
      "Training batch 30\tloss: 24.5027\tacc: 0.0008\r",
      "Training batch 31\tloss: 24.5106\tacc: 0.0008\r",
      "Training batch 32\tloss: 24.5153\tacc: 0.0008\r",
      "Training batch 33\tloss: 24.5231\tacc: 0.0008\r",
      "Training batch 34\tloss: 24.5278\tacc: 0.0007\r",
      "Training batch 35\tloss: 24.5310\tacc: 0.0007\r",
      "Training batch 36\tloss: 24.5353\tacc: 0.0007\r",
      "Training batch 37\tloss: 24.5335\tacc: 0.0007\r",
      "Training batch 38\tloss: 24.5340\tacc: 0.0007\r",
      "Training batch 39\tloss: 24.5374\tacc: 0.0006\r",
      "Training batch 40\tloss: 24.5386\tacc: 0.0006\r",
      "Training batch 41\tloss: 24.5388\tacc: 0.0006\r",
      "Training batch 42\tloss: 24.5405\tacc: 0.0006\r",
      "Training batch 43\tloss: 24.5408\tacc: 0.0006\r",
      "Training batch 44\tloss: 24.5427\tacc: 0.0006\r",
      "Training batch 45\tloss: 24.5414\tacc: 0.0006\r",
      "Training batch 46\tloss: 24.5382\tacc: 0.0005\r",
      "Training batch 47\tloss: 24.5382\tacc: 0.0005\r",
      "Training batch 48\tloss: 24.5379\tacc: 0.0005\r",
      "Training batch 49\tloss: 24.5355\tacc: 0.0005\r",
      "Training batch 50\tloss: 24.5330\tacc: 0.0005\r",
      "Training batch 51\tloss: 24.5323\tacc: 0.0005\r",
      "Training batch 52\tloss: 24.5323\tacc: 0.0005\r",
      "Training batch 53\tloss: 24.5282\tacc: 0.0005\r",
      "Training batch 54\tloss: 24.5269\tacc: 0.0005\r",
      "Training batch 55\tloss: 24.5243\tacc: 0.0005\r",
      "Training batch 56\tloss: 24.5174\tacc: 0.0004\r",
      "Training batch 57\tloss: 24.5124\tacc: 0.0004\r",
      "Training batch 58\tloss: 24.5106\tacc: 0.0004\r",
      "Training batch 59\tloss: 24.5058\tacc: 0.0004\r",
      "Training batch 60\tloss: 24.4999\tacc: 0.0004\r",
      "Training batch 61\tloss: 24.4964\tacc: 0.0004\r",
      "Training batch 62\tloss: 24.4929\tacc: 0.0004\r",
      "Training batch 63\tloss: 24.4863\tacc: 0.0004\r",
      "Training batch 64\tloss: 24.4788\tacc: 0.0004\r",
      "Training batch 65\tloss: 24.4730\tacc: 0.0004\r",
      "Training batch 66\tloss: 24.4642\tacc: 0.0004\r",
      "Training batch 67\tloss: 24.4574\tacc: 0.0004\r",
      "Training batch 68\tloss: 24.4495\tacc: 0.0004\r",
      "Training batch 69\tloss: 24.4434\tacc: 0.0004\r",
      "Training batch 70\tloss: 24.4362\tacc: 0.0004\r",
      "Training batch 71\tloss: 24.4293\tacc: 0.0004\r",
      "Training batch 72\tloss: 24.4233\tacc: 0.0003\r",
      "Training batch 73\tloss: 24.4148\tacc: 0.0003\r",
      "Training batch 74\tloss: 24.4084\tacc: 0.0003\r",
      "Training batch 75\tloss: 24.3993\tacc: 0.0003\r",
      "Training batch 76\tloss: 24.3921\tacc: 0.0003\r",
      "Training batch 77\tloss: 24.3828\tacc: 0.0003\r",
      "Training batch 78\tloss: 24.3744\tacc: 0.0003\r",
      "Training batch 79\tloss: 24.3655\tacc: 0.0003\r",
      "Training batch 80\tloss: 24.3551\tacc: 0.0003\r",
      "Training batch 81\tloss: 24.3464\tacc: 0.0003\r",
      "Training batch 82\tloss: 24.3360\tacc: 0.0003\r",
      "Training batch 83\tloss: 24.3246\tacc: 0.0003\r",
      "Training batch 84\tloss: 24.3147\tacc: 0.0003\r",
      "Training batch 85\tloss: 24.3046\tacc: 0.0003\r",
      "Training batch 86\tloss: 24.2948\tacc: 0.0003\r",
      "Training batch 87\tloss: 24.2833\tacc: 0.0003\r",
      "Training batch 88\tloss: 24.2727\tacc: 0.0003\r",
      "Training batch 89\tloss: 24.2628\tacc: 0.0003\r",
      "Training batch 90\tloss: 24.2513\tacc: 0.0003\r",
      "Training batch 91\tloss: 24.2380\tacc: 0.0003\r",
      "Training batch 92\tloss: 24.2256\tacc: 0.0003\r",
      "Training batch 93\tloss: 24.2137\tacc: 0.0003\r",
      "Training batch 94\tloss: 24.2025\tacc: 0.0003\r",
      "Training batch 95\tloss: 24.1888\tacc: 0.0003\r",
      "Training batch 96\tloss: 24.1763\tacc: 0.0003\r",
      "Training batch 97\tloss: 24.1632\tacc: 0.0003\r",
      "Training batch 98\tloss: 24.1491\tacc: 0.0003\r",
      "Training batch 99\tloss: 24.1365\tacc: 0.0003\r",
      "Training batch 100\tloss: 24.1231\tacc: 0.0002\r",
      "Training batch 101\tloss: 24.1103\tacc: 0.0002\r",
      "Training batch 102\tloss: 24.0972\tacc: 0.0002\r",
      "Training batch 103\tloss: 24.0822\tacc: 0.0002\r",
      "Training batch 104\tloss: 24.0679\tacc: 0.0002\r",
      "Training batch 105\tloss: 24.0539\tacc: 0.0002\r",
      "Training batch 106\tloss: 24.0370\tacc: 0.0002\r",
      "Training batch 107\tloss: 24.0204\tacc: 0.0002\r",
      "Training batch 108\tloss: 24.0058\tacc: 0.0002\r",
      "Training batch 109\tloss: 23.9905\tacc: 0.0002\r",
      "Training batch 110\tloss: 23.9757\tacc: 0.0002\r",
      "Training batch 111\tloss: 23.9592\tacc: 0.0002\r",
      "Training batch 112\tloss: 23.9440\tacc: 0.0002\r",
      "Training batch 113\tloss: 23.9272\tacc: 0.0002\r",
      "Training batch 114\tloss: 23.9100\tacc: 0.0002\r",
      "Training batch 115\tloss: 23.8932\tacc: 0.0002\r",
      "Training batch 116\tloss: 23.8769\tacc: 0.0002\r",
      "Training batch 117\tloss: 23.8594\tacc: 0.0002\r",
      "Training batch 118\tloss: 23.8422\tacc: 0.0002\r",
      "Training batch 119\tloss: 23.8238\tacc: 0.0002\r",
      "Training batch 120\tloss: 23.8052\tacc: 0.0002\r",
      "Training batch 121\tloss: 23.7863\tacc: 0.0002\r",
      "Training batch 122\tloss: 23.7683\tacc: 0.0002\r",
      "Training batch 123\tloss: 23.7495\tacc: 0.0002\r",
      "Training batch 124\tloss: 23.7305\tacc: 0.0002\r",
      "Training batch 125\tloss: 23.7091\tacc: 0.0002\r",
      "Training batch 126\tloss: 23.6891\tacc: 0.0002\r",
      "Training batch 127\tloss: 23.6688\tacc: 0.0002\r",
      "Training batch 128\tloss: 23.6468\tacc: 0.0002\r",
      "Training batch 129\tloss: 23.6255\tacc: 0.0002\r",
      "Training batch 130\tloss: 23.6046\tacc: 0.0002\r",
      "Training batch 131\tloss: 23.5837\tacc: 0.0002\r",
      "Training batch 132\tloss: 23.5620\tacc: 0.0002\r",
      "Training batch 133\tloss: 23.5407\tacc: 0.0002\r",
      "Training batch 134\tloss: 23.5181\tacc: 0.0002\r",
      "Training batch 135\tloss: 23.4952\tacc: 0.0002\r",
      "Training batch 136\tloss: 23.4720\tacc: 0.0002\r",
      "Training batch 137\tloss: 23.4481\tacc: 0.0002\r",
      "Training batch 138\tloss: 23.4238\tacc: 0.0002\r",
      "Training batch 139\tloss: 23.3987\tacc: 0.0002\r",
      "Training batch 140\tloss: 23.3753\tacc: 0.0002\r",
      "Training batch 141\tloss: 23.3516\tacc: 0.0002\r",
      "Training batch 142\tloss: 23.3264\tacc: 0.0002\r",
      "Training batch 143\tloss: 23.3005\tacc: 0.0002\r",
      "Training batch 144\tloss: 23.2735\tacc: 0.0002\r",
      "Training batch 145\tloss: 23.2468\tacc: 0.0002\r",
      "Training batch 146\tloss: 23.2203\tacc: 0.0002\r",
      "Training batch 147\tloss: 23.1918\tacc: 0.0002\r",
      "Training batch 148\tloss: 23.1645\tacc: 0.0002\r",
      "Training batch 149\tloss: 23.1376\tacc: 0.0002\r",
      "Training batch 150\tloss: 23.1092\tacc: 0.0002\r",
      "Training batch 151\tloss: 23.0805\tacc: 0.0002\r",
      "Training batch 152\tloss: 23.0518\tacc: 0.0002\r",
      "Training batch 153\tloss: 23.0215\tacc: 0.0002\r",
      "Training batch 154\tloss: 22.9907\tacc: 0.0002\r",
      "Training batch 155\tloss: 22.9596\tacc: 0.0002\r",
      "Training batch 156\tloss: 22.9262\tacc: 0.0002\r",
      "Training batch 157\tloss: 22.8961\tacc: 0.0002\r",
      "Training batch 158\tloss: 22.8629\tacc: 0.0002\r",
      "Training batch 159\tloss: 22.8288\tacc: 0.0002\r",
      "Training batch 160\tloss: 22.7948\tacc: 0.0002\r",
      "Training batch 161\tloss: 22.7628\tacc: 0.0002\r",
      "Training batch 162\tloss: 22.7271\tacc: 0.0002\r",
      "Training batch 163\tloss: 22.6908\tacc: 0.0002\r",
      "Training batch 164\tloss: 22.6549\tacc: 0.0002\r",
      "Training batch 165\tloss: 22.6188\tacc: 0.0002\r",
      "Training batch 166\tloss: 22.5809\tacc: 0.0001\r",
      "Training batch 167\tloss: 22.5439\tacc: 0.0001\r",
      "Training batch 168\tloss: 22.5054\tacc: 0.0001\r",
      "Training batch 169\tloss: 22.4667\tacc: 0.0001\r",
      "Training batch 170\tloss: 22.4270\tacc: 0.0001\r",
      "Training batch 171\tloss: 22.3854\tacc: 0.0001\r",
      "Training batch 172\tloss: 22.3419\tacc: 0.0001\r",
      "Training batch 173\tloss: 22.2987\tacc: 0.0001\r",
      "Training batch 174\tloss: 22.2558\tacc: 0.0001\r",
      "Training batch 175\tloss: 22.2107\tacc: 0.0001\r",
      "Training batch 176\tloss: 22.1645\tacc: 0.0001\r",
      "Training batch 177\tloss: 22.1194\tacc: 0.0001\r",
      "Training batch 178\tloss: 22.0741\tacc: 0.0001\r",
      "Training batch 179\tloss: 22.0263\tacc: 0.0001\r",
      "Training batch 180\tloss: 21.9772\tacc: 0.0001\r",
      "Training batch 181\tloss: 21.9295\tacc: 0.0001\r",
      "Training batch 182\tloss: 21.8781\tacc: 0.0001\r",
      "Training batch 183\tloss: 21.8274\tacc: 0.0001\r",
      "Training batch 184\tloss: 21.7766\tacc: 0.0001\r",
      "Training batch 185\tloss: 21.7219\tacc: 0.0001\r",
      "Training batch 186\tloss: 21.6699\tacc: 0.0001\r",
      "Training batch 187\tloss: 21.6142\tacc: 0.0001\r",
      "Training batch 188\tloss: 21.5539\tacc: 0.0001\r",
      "Training batch 189\tloss: 21.4963\tacc: 0.0001\r",
      "Training batch 190\tloss: 21.4371\tacc: 0.0001\r",
      "Training batch 191\tloss: 21.3788\tacc: 0.0001\r",
      "Training batch 192\tloss: 21.3182\tacc: 0.0001\r",
      "Training batch 193\tloss: 21.2569\tacc: 0.0001\r",
      "Training batch 194\tloss: 21.1956\tacc: 0.0001\r",
      "Training batch 195\tloss: 21.1336\tacc: 0.0001\r",
      "Training batch 196\tloss: 21.0678\tacc: 0.0001\r",
      "Training batch 197\tloss: 21.0031\tacc: 0.0001\r",
      "Training batch 198\tloss: 20.9396\tacc: 0.0001\r",
      "Training batch 199\tloss: 20.8734\tacc: 0.0001\r",
      "Training batch 200\tloss: 20.8049\tacc: 0.0002\r",
      "Training batch 201\tloss: 20.7350\tacc: 0.0004\r",
      "Training batch 202\tloss: 20.6662\tacc: 0.0009\r",
      "Training batch 203\tloss: 20.6018\tacc: 0.0013\r",
      "Training batch 204\tloss: 20.5340\tacc: 0.0020\r",
      "Training batch 205\tloss: 20.4663\tacc: 0.0028\r",
      "Training batch 206\tloss: 20.3981\tacc: 0.0036\r",
      "Training batch 207\tloss: 20.3345\tacc: 0.0044\r",
      "Training batch 208\tloss: 20.2659\tacc: 0.0053\r",
      "Training batch 209\tloss: 20.1997\tacc: 0.0061\r",
      "Training batch 210\tloss: 20.1313\tacc: 0.0070\r",
      "Training batch 211\tloss: 20.0635\tacc: 0.0079\r",
      "Training batch 212\tloss: 19.9987\tacc: 0.0087\r",
      "Training batch 213\tloss: 19.9297\tacc: 0.0096\r",
      "Training batch 214\tloss: 19.8638\tacc: 0.0105\r",
      "Training batch 215\tloss: 19.7972\tacc: 0.0113\r",
      "Training batch 216\tloss: 19.7252\tacc: 0.0122\r",
      "Training batch 217\tloss: 19.6586\tacc: 0.0130\r",
      "Training batch 218\tloss: 19.5909\tacc: 0.0138\r",
      "Training batch 219\tloss: 19.5240\tacc: 0.0147\r",
      "Training batch 220\tloss: 19.4569\tacc: 0.0154\r",
      "Training batch 221\tloss: 19.3879\tacc: 0.0161\r",
      "Training batch 222\tloss: 19.3264\tacc: 0.0167\r",
      "Training batch 223\tloss: 19.2628\tacc: 0.0173\r",
      "Training batch 224\tloss: 19.1942\tacc: 0.0180\r",
      "Training batch 225\tloss: 19.1287\tacc: 0.0185\r",
      "Training batch 226\tloss: 19.0675\tacc: 0.0189\r",
      "Training batch 227\tloss: 19.0066\tacc: 0.0193\r",
      "Training batch 228\tloss: 18.9416\tacc: 0.0197\r",
      "Training batch 229\tloss: 18.8798\tacc: 0.0200\r",
      "Training batch 230\tloss: 18.8197\tacc: 0.0202\r",
      "Training batch 231\tloss: 18.7595\tacc: 0.0205\r",
      "Training batch 232\tloss: 18.7006\tacc: 0.0208\r",
      "Training batch 233\tloss: 18.6424\tacc: 0.0210\r",
      "Training batch 234\tloss: 18.5847\tacc: 0.0212\r",
      "Training batch 235\tloss: 18.5236\tacc: 0.0214\r",
      "Training batch 236\tloss: 18.4627\tacc: 0.0216\r",
      "Training batch 237\tloss: 18.4035\tacc: 0.0218\r",
      "Training batch 238\tloss: 18.3427\tacc: 0.0220\r",
      "Training batch 239\tloss: 18.2845\tacc: 0.0221\r",
      "Training batch 240\tloss: 18.2281\tacc: 0.0222\r",
      "Training batch 241\tloss: 18.1678\tacc: 0.0224\r",
      "Training batch 242\tloss: 18.1120\tacc: 0.0226\r",
      "Training batch 243\tloss: 18.0532\tacc: 0.0228\r",
      "Training batch 244\tloss: 17.9972\tacc: 0.0230\r",
      "Training batch 245\tloss: 17.9430\tacc: 0.0232\r",
      "Training batch 246\tloss: 17.8885\tacc: 0.0234\r",
      "Training batch 247\tloss: 17.8343\tacc: 0.0236\r",
      "Training batch 248\tloss: 17.7789\tacc: 0.0238\r",
      "Training batch 249\tloss: 17.7249\tacc: 0.0241\r",
      "Training batch 250\tloss: 17.6713\tacc: 0.0244\r",
      "Training batch 251\tloss: 17.6175\tacc: 0.0247\r",
      "Training batch 252\tloss: 17.5656\tacc: 0.0250\r",
      "Training batch 253\tloss: 17.5102\tacc: 0.0253\r",
      "Training batch 254\tloss: 17.4587\tacc: 0.0256\r",
      "Training batch 255\tloss: 17.4091\tacc: 0.0260\r",
      "Training batch 256\tloss: 17.3572\tacc: 0.0264\r",
      "Training batch 257\tloss: 17.3029\tacc: 0.0267\r",
      "Training batch 258\tloss: 17.2479\tacc: 0.0272\r",
      "Training batch 259\tloss: 17.1995\tacc: 0.0276\r",
      "Training batch 260\tloss: 17.1478\tacc: 0.0281\r",
      "Training batch 261\tloss: 17.0984\tacc: 0.0286\r",
      "Training batch 262\tloss: 17.0460\tacc: 0.0291\r",
      "Training batch 263\tloss: 16.9981\tacc: 0.0295\r",
      "Training batch 264\tloss: 16.9491\tacc: 0.0301\r",
      "Training batch 265\tloss: 16.8993\tacc: 0.0306\r",
      "Training batch 266\tloss: 16.8500\tacc: 0.0312\r",
      "Training batch 267\tloss: 16.8010\tacc: 0.0317\r",
      "Training batch 268\tloss: 16.7529\tacc: 0.0322\r",
      "Training batch 269\tloss: 16.7045\tacc: 0.0327\r",
      "Training batch 270\tloss: 16.6904\tacc: 0.0328\ttime: 71.505 s\n",
      "\r",
      "Validation batch 1\tloss: 3.7284\tacc: 0.2188\r",
      "Validation batch 2\tloss: 3.6687\tacc: 0.2097\r",
      "Validation batch 3\tloss: 3.6818\tacc: 0.2115\r",
      "Validation batch 4\tloss: 3.6866\tacc: 0.2096\r",
      "Validation batch 5\tloss: 3.7051\tacc: 0.2054\r",
      "Validation batch 6\tloss: 3.7073\tacc: 0.2039\r",
      "Validation batch 7\tloss: 3.7197\tacc: 0.2007\r",
      "Validation batch 8\tloss: 3.7039\tacc: 0.2015\r",
      "Validation batch 9\tloss: 3.6893\tacc: 0.2027\r",
      "Validation batch 10\tloss: 3.6972\tacc: 0.2020\r",
      "Validation batch 11\tloss: 3.7059\tacc: 0.2005\r",
      "Validation batch 12\tloss: 3.7049\tacc: 0.2013\r",
      "Validation batch 13\tloss: 3.7022\tacc: 0.2009\r",
      "Validation batch 14\tloss: 3.7032\tacc: 0.2016\r",
      "Validation batch 15\tloss: 3.7062\tacc: 0.2012\r",
      "Validation batch 16\tloss: 3.7047\tacc: 0.2005\r",
      "Validation batch 17\tloss: 3.7029\tacc: 0.2002\r",
      "Validation batch 18\tloss: 3.7049\tacc: 0.1997\r",
      "Validation batch 19\tloss: 3.7007\tacc: 0.1986\r",
      "Validation batch 20\tloss: 3.6990\tacc: 0.1984\r",
      "Validation batch 21\tloss: 3.6925\tacc: 0.1993\r",
      "Validation batch 22\tloss: 3.6937\tacc: 0.1997\r",
      "Validation batch 23\tloss: 3.7006\tacc: 0.1996\r",
      "Validation batch 24\tloss: 3.7029\tacc: 0.1999\r",
      "Validation batch 25\tloss: 3.6982\tacc: 0.1996\r",
      "Validation batch 26\tloss: 3.6949\tacc: 0.2002\r",
      "Validation batch 27\tloss: 3.6973\tacc: 0.2001\r",
      "Validation batch 28\tloss: 3.6995\tacc: 0.2002\r",
      "Validation batch 29\tloss: 3.6981\tacc: 0.2002\r",
      "Validation batch 30\tloss: 3.7019\tacc: 0.1993\r",
      "Validation batch 31\tloss: 3.6988\tacc: 0.1998\r",
      "Validation batch 32\tloss: 3.7014\tacc: 0.1995\r",
      "Validation batch 33\tloss: 3.7013\tacc: 0.1995\r",
      "Validation batch 34\tloss: 3.7019\tacc: 0.1992\r",
      "Validation batch 35\tloss: 3.7044\tacc: 0.1992\r",
      "Validation batch 36\tloss: 3.7077\tacc: 0.1987\r",
      "Validation batch 37\tloss: 3.7069\tacc: 0.1988\r",
      "Validation batch 38\tloss: 3.7073\tacc: 0.1989\r",
      "Validation batch 39\tloss: 3.7087\tacc: 0.1987\r",
      "Validation batch 40\tloss: 3.7093\tacc: 0.1983\r",
      "Validation batch 41\tloss: 3.7107\tacc: 0.1983\r",
      "Validation batch 42\tloss: 3.7117\tacc: 0.1985\r",
      "Validation batch 43\tloss: 3.7161\tacc: 0.1985\r",
      "Validation batch 44\tloss: 3.7164\tacc: 0.1988\r",
      "Validation batch 45\tloss: 3.7160\tacc: 0.1986\r",
      "Validation batch 46\tloss: 3.7162\tacc: 0.1986\r",
      "Validation batch 47\tloss: 3.7141\tacc: 0.1986\r",
      "Validation batch 48\tloss: 3.7144\tacc: 0.1990\r",
      "Validation batch 49\tloss: 3.7146\tacc: 0.1992\r",
      "Validation batch 50\tloss: 3.7162\tacc: 0.1990\r",
      "Validation batch 51\tloss: 3.7157\tacc: 0.1990\r",
      "Validation batch 52\tloss: 3.7144\tacc: 0.1993\r",
      "Validation batch 53\tloss: 3.7173\tacc: 0.1989\r",
      "Validation batch 54\tloss: 3.7195\tacc: 0.1987\r",
      "Validation batch 55\tloss: 3.7191\tacc: 0.1989\r",
      "Validation batch 56\tloss: 3.7164\tacc: 0.1990\r",
      "Validation batch 57\tloss: 3.7155\tacc: 0.1988\r",
      "Validation batch 58\tloss: 3.7155\tacc: 0.1989\r",
      "Validation batch 59\tloss: 3.7149\tacc: 0.1990\r",
      "Validation batch 60\tloss: 3.7135\tacc: 0.1990\r",
      "Validation batch 61\tloss: 3.7130\tacc: 0.1990\r",
      "Validation batch 62\tloss: 3.7138\tacc: 0.1990\r",
      "Validation batch 63\tloss: 3.7131\tacc: 0.1990\r",
      "Validation batch 64\tloss: 3.7124\tacc: 0.1986\r",
      "Validation batch 65\tloss: 3.7126\tacc: 0.1985\r",
      "Validation batch 66\tloss: 3.7118\tacc: 0.1987\r",
      "Validation batch 67\tloss: 3.7097\tacc: 0.1991\r",
      "Validation batch 68\tloss: 3.7108\tacc: 0.1991\r",
      "Validation batch 69\tloss: 3.7102\tacc: 0.1990\r",
      "Validation batch 70\tloss: 3.7109\tacc: 0.1988\r",
      "Validation batch 71\tloss: 3.7114\tacc: 0.1987\r",
      "Validation batch 72\tloss: 3.7116\tacc: 0.1987\r",
      "Validation batch 73\tloss: 3.7126\tacc: 0.1987\r",
      "Validation batch 74\tloss: 3.7125\tacc: 0.1987\r",
      "Validation batch 75\tloss: 3.7131\tacc: 0.1988\r",
      "Validation batch 76\tloss: 3.7133\tacc: 0.1989\r",
      "Validation batch 77\tloss: 3.7124\tacc: 0.1988\r",
      "Validation batch 78\tloss: 3.7115\tacc: 0.1989\r",
      "Validation batch 79\tloss: 3.7095\tacc: 0.1990\r",
      "Validation batch 80\tloss: 3.7108\tacc: 0.1990\r",
      "Validation batch 81\tloss: 3.7118\tacc: 0.1991\r",
      "Validation batch 82\tloss: 3.7124\tacc: 0.1990\r",
      "Validation batch 83\tloss: 3.7128\tacc: 0.1989\r",
      "Validation batch 84\tloss: 3.7125\tacc: 0.1989\r",
      "Validation batch 85\tloss: 3.7124\tacc: 0.1990\r",
      "Validation batch 86\tloss: 3.7131\tacc: 0.1989\r",
      "Validation batch 87\tloss: 3.7122\tacc: 0.1991\r",
      "Validation batch 88\tloss: 3.7114\tacc: 0.1990\r",
      "Validation batch 89\tloss: 3.7119\tacc: 0.1990\r",
      "Validation batch 90\tloss: 3.7116\tacc: 0.1989\ttime: 7.722 s\n",
      "The chkpt file has been updated at epoch 1.\n",
      "Epoch 2 of 5 \n",
      "\r",
      "Training batch 1\tloss: 3.7023\tacc: 0.1664\r",
      "Training batch 2\tloss: 3.6638\tacc: 0.1706\r",
      "Training batch 3\tloss: 3.7423\tacc: 0.1696\r",
      "Training batch 4\tloss: 3.7691\tacc: 0.1685\r",
      "Training batch 5\tloss: 3.7436\tacc: 0.1714\r",
      "Training batch 6\tloss: 3.7359\tacc: 0.1736\r",
      "Training batch 7\tloss: 3.7345\tacc: 0.1753\r",
      "Training batch 8\tloss: 3.7121\tacc: 0.1737\r",
      "Training batch 9\tloss: 3.6984\tacc: 0.1733\r",
      "Training batch 10\tloss: 3.6945\tacc: 0.1741\r",
      "Training batch 11\tloss: 3.6921\tacc: 0.1746\r",
      "Training batch 12\tloss: 3.6866\tacc: 0.1752\r",
      "Training batch 13\tloss: 3.6746\tacc: 0.1762\r",
      "Training batch 14\tloss: 3.6720\tacc: 0.1778\r",
      "Training batch 15\tloss: 3.6708\tacc: 0.1765\r",
      "Training batch 16\tloss: 3.6608\tacc: 0.1771\r",
      "Training batch 17\tloss: 3.6619\tacc: 0.1772\r",
      "Training batch 18\tloss: 3.6561\tacc: 0.1782\r",
      "Training batch 19\tloss: 3.6459\tacc: 0.1788\r",
      "Training batch 20\tloss: 3.6370\tacc: 0.1795\r",
      "Training batch 21\tloss: 3.6315\tacc: 0.1792\r",
      "Training batch 22\tloss: 3.6243\tacc: 0.1798\r",
      "Training batch 23\tloss: 3.6168\tacc: 0.1798\r",
      "Training batch 24\tloss: 3.6077\tacc: 0.1796\r",
      "Training batch 25\tloss: 3.5988\tacc: 0.1800\r",
      "Training batch 26\tloss: 3.5896\tacc: 0.1803\r",
      "Training batch 27\tloss: 3.5811\tacc: 0.1808\r",
      "Training batch 28\tloss: 3.5744\tacc: 0.1809\r",
      "Training batch 29\tloss: 3.5677\tacc: 0.1812\r",
      "Training batch 30\tloss: 3.5587\tacc: 0.1822\r",
      "Training batch 31\tloss: 3.5549\tacc: 0.1821\r",
      "Training batch 32\tloss: 3.5460\tacc: 0.1824\r",
      "Training batch 33\tloss: 3.5400\tacc: 0.1825\r",
      "Training batch 34\tloss: 3.5338\tacc: 0.1826\r",
      "Training batch 35\tloss: 3.5270\tacc: 0.1832\r",
      "Training batch 36\tloss: 3.5234\tacc: 0.1835\r",
      "Training batch 37\tloss: 3.5165\tacc: 0.1838\r",
      "Training batch 38\tloss: 3.5112\tacc: 0.1841\r",
      "Training batch 39\tloss: 3.5065\tacc: 0.1838\r",
      "Training batch 40\tloss: 3.5005\tacc: 0.1841\r",
      "Training batch 41\tloss: 3.4945\tacc: 0.1843\r",
      "Training batch 42\tloss: 3.4892\tacc: 0.1847\r",
      "Training batch 43\tloss: 3.4821\tacc: 0.1848\r",
      "Training batch 44\tloss: 3.4759\tacc: 0.1845\r",
      "Training batch 45\tloss: 3.4719\tacc: 0.1846\r",
      "Training batch 46\tloss: 3.4653\tacc: 0.1850\r",
      "Training batch 47\tloss: 3.4582\tacc: 0.1852\r",
      "Training batch 48\tloss: 3.4543\tacc: 0.1854\r",
      "Training batch 49\tloss: 3.4481\tacc: 0.1856\r",
      "Training batch 50\tloss: 3.4455\tacc: 0.1857\r",
      "Training batch 51\tloss: 3.4405\tacc: 0.1860\r",
      "Training batch 52\tloss: 3.4354\tacc: 0.1862\r",
      "Training batch 53\tloss: 3.4301\tacc: 0.1864\r",
      "Training batch 54\tloss: 3.4238\tacc: 0.1867\r",
      "Training batch 55\tloss: 3.4181\tacc: 0.1871\r",
      "Training batch 56\tloss: 3.4136\tacc: 0.1869\r",
      "Training batch 57\tloss: 3.4070\tacc: 0.1872\r",
      "Training batch 58\tloss: 3.4009\tacc: 0.1875\r",
      "Training batch 59\tloss: 3.3956\tacc: 0.1876\r",
      "Training batch 60\tloss: 3.3905\tacc: 0.1878\r",
      "Training batch 61\tloss: 3.3853\tacc: 0.1882\r",
      "Training batch 62\tloss: 3.3805\tacc: 0.1884\r",
      "Training batch 63\tloss: 3.3740\tacc: 0.1887\r",
      "Training batch 64\tloss: 3.3687\tacc: 0.1888\r",
      "Training batch 65\tloss: 3.3631\tacc: 0.1889\r",
      "Training batch 66\tloss: 3.3582\tacc: 0.1894\r",
      "Training batch 67\tloss: 3.3530\tacc: 0.1898\r",
      "Training batch 68\tloss: 3.3476\tacc: 0.1898\r",
      "Training batch 69\tloss: 3.3432\tacc: 0.1902\r",
      "Training batch 70\tloss: 3.3386\tacc: 0.1905\r",
      "Training batch 71\tloss: 3.3336\tacc: 0.1910\r",
      "Training batch 72\tloss: 3.3282\tacc: 0.1912\r",
      "Training batch 73\tloss: 3.3229\tacc: 0.1916\r",
      "Training batch 74\tloss: 3.3180\tacc: 0.1920\r",
      "Training batch 75\tloss: 3.3124\tacc: 0.1923\r",
      "Training batch 76\tloss: 3.3070\tacc: 0.1928\r",
      "Training batch 77\tloss: 3.3030\tacc: 0.1930\r",
      "Training batch 78\tloss: 3.2977\tacc: 0.1932\r",
      "Training batch 79\tloss: 3.2920\tacc: 0.1933\r",
      "Training batch 80\tloss: 3.2875\tacc: 0.1933\r",
      "Training batch 81\tloss: 3.2835\tacc: 0.1933\r",
      "Training batch 82\tloss: 3.2790\tacc: 0.1935\r",
      "Training batch 83\tloss: 3.2744\tacc: 0.1938\r",
      "Training batch 84\tloss: 3.2705\tacc: 0.1940\r",
      "Training batch 85\tloss: 3.2662\tacc: 0.1943\r",
      "Training batch 86\tloss: 3.2619\tacc: 0.1944\r",
      "Training batch 87\tloss: 3.2561\tacc: 0.1948\r",
      "Training batch 88\tloss: 3.2520\tacc: 0.1951\r",
      "Training batch 89\tloss: 3.2478\tacc: 0.1953\r",
      "Training batch 90\tloss: 3.2434\tacc: 0.1957\r",
      "Training batch 91\tloss: 3.2391\tacc: 0.1961\r",
      "Training batch 92\tloss: 3.2349\tacc: 0.1963\r",
      "Training batch 93\tloss: 3.2308\tacc: 0.1964\r",
      "Training batch 94\tloss: 3.2267\tacc: 0.1967\r",
      "Training batch 95\tloss: 3.2233\tacc: 0.1969\r",
      "Training batch 96\tloss: 3.2186\tacc: 0.1971\r",
      "Training batch 97\tloss: 3.2149\tacc: 0.1973\r",
      "Training batch 98\tloss: 3.2109\tacc: 0.1974\r",
      "Training batch 99\tloss: 3.2079\tacc: 0.1977\r",
      "Training batch 100\tloss: 3.2043\tacc: 0.1978\r",
      "Training batch 101\tloss: 3.2003\tacc: 0.1980\r",
      "Training batch 102\tloss: 3.1971\tacc: 0.1980\r",
      "Training batch 103\tloss: 3.1940\tacc: 0.1981\r",
      "Training batch 104\tloss: 3.1899\tacc: 0.1983\r",
      "Training batch 105\tloss: 3.1867\tacc: 0.1985\r",
      "Training batch 106\tloss: 3.1831\tacc: 0.1987\r",
      "Training batch 107\tloss: 3.1802\tacc: 0.1989\r",
      "Training batch 108\tloss: 3.1763\tacc: 0.1992\r",
      "Training batch 109\tloss: 3.1729\tacc: 0.1994\r",
      "Training batch 110\tloss: 3.1692\tacc: 0.1996\r",
      "Training batch 111\tloss: 3.1657\tacc: 0.1998\r",
      "Training batch 112\tloss: 3.1625\tacc: 0.1999\r",
      "Training batch 113\tloss: 3.1595\tacc: 0.2000\r",
      "Training batch 114\tloss: 3.1561\tacc: 0.2002\r",
      "Training batch 115\tloss: 3.1529\tacc: 0.2004\r",
      "Training batch 116\tloss: 3.1498\tacc: 0.2007\r",
      "Training batch 117\tloss: 3.1468\tacc: 0.2008\r",
      "Training batch 118\tloss: 3.1435\tacc: 0.2010\r",
      "Training batch 119\tloss: 3.1403\tacc: 0.2013\r",
      "Training batch 120\tloss: 3.1371\tacc: 0.2015\r",
      "Training batch 121\tloss: 3.1348\tacc: 0.2016\r",
      "Training batch 122\tloss: 3.1318\tacc: 0.2019\r",
      "Training batch 123\tloss: 3.1293\tacc: 0.2019\r",
      "Training batch 124\tloss: 3.1264\tacc: 0.2022\r",
      "Training batch 125\tloss: 3.1232\tacc: 0.2024\r",
      "Training batch 126\tloss: 3.1207\tacc: 0.2025\r",
      "Training batch 127\tloss: 3.1176\tacc: 0.2026\r",
      "Training batch 128\tloss: 3.1150\tacc: 0.2028\r",
      "Training batch 129\tloss: 3.1126\tacc: 0.2030\r",
      "Training batch 130\tloss: 3.1100\tacc: 0.2032\r",
      "Training batch 131\tloss: 3.1072\tacc: 0.2033\r",
      "Training batch 132\tloss: 3.1045\tacc: 0.2035\r",
      "Training batch 133\tloss: 3.1018\tacc: 0.2037\r",
      "Training batch 134\tloss: 3.0993\tacc: 0.2039\r",
      "Training batch 135\tloss: 3.0967\tacc: 0.2040\r",
      "Training batch 136\tloss: 3.0938\tacc: 0.2043\r",
      "Training batch 137\tloss: 3.0913\tacc: 0.2044\r",
      "Training batch 138\tloss: 3.0885\tacc: 0.2046\r",
      "Training batch 139\tloss: 3.0861\tacc: 0.2048\r",
      "Training batch 140\tloss: 3.0834\tacc: 0.2050\r",
      "Training batch 141\tloss: 3.0805\tacc: 0.2052\r",
      "Training batch 142\tloss: 3.0780\tacc: 0.2054\r",
      "Training batch 143\tloss: 3.0756\tacc: 0.2056\r",
      "Training batch 144\tloss: 3.0731\tacc: 0.2058\r",
      "Training batch 145\tloss: 3.0705\tacc: 0.2061\r",
      "Training batch 146\tloss: 3.0680\tacc: 0.2063\r",
      "Training batch 147\tloss: 3.0659\tacc: 0.2065\r",
      "Training batch 148\tloss: 3.0636\tacc: 0.2068\r",
      "Training batch 149\tloss: 3.0613\tacc: 0.2070\r",
      "Training batch 150\tloss: 3.0593\tacc: 0.2071\r",
      "Training batch 151\tloss: 3.0571\tacc: 0.2073\r",
      "Training batch 152\tloss: 3.0546\tacc: 0.2074\r",
      "Training batch 153\tloss: 3.0525\tacc: 0.2075\r",
      "Training batch 154\tloss: 3.0499\tacc: 0.2078\r",
      "Training batch 155\tloss: 3.0479\tacc: 0.2078\r",
      "Training batch 156\tloss: 3.0455\tacc: 0.2080\r",
      "Training batch 157\tloss: 3.0432\tacc: 0.2083\r",
      "Training batch 158\tloss: 3.0411\tacc: 0.2084\r",
      "Training batch 159\tloss: 3.0395\tacc: 0.2084\r",
      "Training batch 160\tloss: 3.0375\tacc: 0.2086\r",
      "Training batch 161\tloss: 3.0353\tacc: 0.2088\r",
      "Training batch 162\tloss: 3.0333\tacc: 0.2089\r",
      "Training batch 163\tloss: 3.0309\tacc: 0.2091\r",
      "Training batch 164\tloss: 3.0287\tacc: 0.2093\r",
      "Training batch 165\tloss: 3.0265\tacc: 0.2094\r",
      "Training batch 166\tloss: 3.0247\tacc: 0.2095\r",
      "Training batch 167\tloss: 3.0227\tacc: 0.2097\r",
      "Training batch 168\tloss: 3.0207\tacc: 0.2098\r",
      "Training batch 169\tloss: 3.0186\tacc: 0.2099\r",
      "Training batch 170\tloss: 3.0167\tacc: 0.2099\r",
      "Training batch 171\tloss: 3.0147\tacc: 0.2100\r",
      "Training batch 172\tloss: 3.0128\tacc: 0.2103\r",
      "Training batch 173\tloss: 3.0109\tacc: 0.2104\r",
      "Training batch 174\tloss: 3.0093\tacc: 0.2104\r",
      "Training batch 175\tloss: 3.0075\tacc: 0.2105\r",
      "Training batch 176\tloss: 3.0056\tacc: 0.2106\r",
      "Training batch 177\tloss: 3.0034\tacc: 0.2108\r",
      "Training batch 178\tloss: 3.0018\tacc: 0.2108\r",
      "Training batch 179\tloss: 3.0002\tacc: 0.2110\r",
      "Training batch 180\tloss: 2.9983\tacc: 0.2109\r",
      "Training batch 181\tloss: 2.9964\tacc: 0.2111\r",
      "Training batch 182\tloss: 2.9946\tacc: 0.2113\r",
      "Training batch 183\tloss: 2.9927\tacc: 0.2114\r",
      "Training batch 184\tloss: 2.9910\tacc: 0.2115\r",
      "Training batch 185\tloss: 2.9892\tacc: 0.2116\r",
      "Training batch 186\tloss: 2.9873\tacc: 0.2117\r",
      "Training batch 187\tloss: 2.9854\tacc: 0.2119\r",
      "Training batch 188\tloss: 2.9837\tacc: 0.2120\r",
      "Training batch 189\tloss: 2.9819\tacc: 0.2121\r",
      "Training batch 190\tloss: 2.9803\tacc: 0.2122\r",
      "Training batch 191\tloss: 2.9785\tacc: 0.2123\r",
      "Training batch 192\tloss: 2.9769\tacc: 0.2124\r",
      "Training batch 193\tloss: 2.9752\tacc: 0.2125\r",
      "Training batch 194\tloss: 2.9734\tacc: 0.2127\r",
      "Training batch 195\tloss: 2.9717\tacc: 0.2128\r",
      "Training batch 196\tloss: 2.9700\tacc: 0.2130\r",
      "Training batch 197\tloss: 2.9682\tacc: 0.2131\r",
      "Training batch 198\tloss: 2.9666\tacc: 0.2132\r",
      "Training batch 199\tloss: 2.9652\tacc: 0.2133\r",
      "Training batch 200\tloss: 2.9636\tacc: 0.2134\r",
      "Training batch 201\tloss: 2.9620\tacc: 0.2135\r",
      "Training batch 202\tloss: 2.9604\tacc: 0.2137\r",
      "Training batch 203\tloss: 2.9588\tacc: 0.2138\r",
      "Training batch 204\tloss: 2.9572\tacc: 0.2140\r",
      "Training batch 205\tloss: 2.9556\tacc: 0.2141\r",
      "Training batch 206\tloss: 2.9542\tacc: 0.2143\r",
      "Training batch 207\tloss: 2.9525\tacc: 0.2143\r",
      "Training batch 208\tloss: 2.9511\tacc: 0.2144\r",
      "Training batch 209\tloss: 2.9493\tacc: 0.2146\r",
      "Training batch 210\tloss: 2.9478\tacc: 0.2147\r",
      "Training batch 211\tloss: 2.9464\tacc: 0.2148\r",
      "Training batch 212\tloss: 2.9448\tacc: 0.2149\r",
      "Training batch 213\tloss: 2.9432\tacc: 0.2151\r",
      "Training batch 214\tloss: 2.9417\tacc: 0.2153\r",
      "Training batch 215\tloss: 2.9404\tacc: 0.2153\r",
      "Training batch 216\tloss: 2.9389\tacc: 0.2154\r",
      "Training batch 217\tloss: 2.9375\tacc: 0.2155\r",
      "Training batch 218\tloss: 2.9361\tacc: 0.2157\r",
      "Training batch 219\tloss: 2.9347\tacc: 0.2158\r",
      "Training batch 220\tloss: 2.9332\tacc: 0.2160\r",
      "Training batch 221\tloss: 2.9320\tacc: 0.2160\r",
      "Training batch 222\tloss: 2.9305\tacc: 0.2162\r",
      "Training batch 223\tloss: 2.9290\tacc: 0.2163\r",
      "Training batch 224\tloss: 2.9278\tacc: 0.2164\r",
      "Training batch 225\tloss: 2.9262\tacc: 0.2166\r",
      "Training batch 226\tloss: 2.9247\tacc: 0.2167\r",
      "Training batch 227\tloss: 2.9233\tacc: 0.2169\r",
      "Training batch 228\tloss: 2.9219\tacc: 0.2169\r",
      "Training batch 229\tloss: 2.9203\tacc: 0.2170\r",
      "Training batch 230\tloss: 2.9191\tacc: 0.2171\r",
      "Training batch 231\tloss: 2.9178\tacc: 0.2172\r",
      "Training batch 232\tloss: 2.9166\tacc: 0.2173\r",
      "Training batch 233\tloss: 2.9153\tacc: 0.2174\r",
      "Training batch 234\tloss: 2.9141\tacc: 0.2175\r",
      "Training batch 235\tloss: 2.9127\tacc: 0.2176\r",
      "Training batch 236\tloss: 2.9113\tacc: 0.2176\r",
      "Training batch 237\tloss: 2.9099\tacc: 0.2178\r",
      "Training batch 238\tloss: 2.9084\tacc: 0.2180\r",
      "Training batch 239\tloss: 2.9074\tacc: 0.2180\r",
      "Training batch 240\tloss: 2.9061\tacc: 0.2181\r",
      "Training batch 241\tloss: 2.9048\tacc: 0.2182\r",
      "Training batch 242\tloss: 2.9035\tacc: 0.2183\r",
      "Training batch 243\tloss: 2.9023\tacc: 0.2184\r",
      "Training batch 244\tloss: 2.9010\tacc: 0.2185\r",
      "Training batch 245\tloss: 2.8997\tacc: 0.2186\r",
      "Training batch 246\tloss: 2.8983\tacc: 0.2187\r",
      "Training batch 247\tloss: 2.8970\tacc: 0.2188\r",
      "Training batch 248\tloss: 2.8958\tacc: 0.2190\r",
      "Training batch 249\tloss: 2.8945\tacc: 0.2191\r",
      "Training batch 250\tloss: 2.8934\tacc: 0.2191\r",
      "Training batch 251\tloss: 2.8920\tacc: 0.2192\r",
      "Training batch 252\tloss: 2.8909\tacc: 0.2193\r",
      "Training batch 253\tloss: 2.8895\tacc: 0.2194\r",
      "Training batch 254\tloss: 2.8883\tacc: 0.2196\r",
      "Training batch 255\tloss: 2.8871\tacc: 0.2196\r",
      "Training batch 256\tloss: 2.8858\tacc: 0.2197\r",
      "Training batch 257\tloss: 2.8847\tacc: 0.2198\r",
      "Training batch 258\tloss: 2.8836\tacc: 0.2199\r",
      "Training batch 259\tloss: 2.8825\tacc: 0.2200\r",
      "Training batch 260\tloss: 2.8812\tacc: 0.2201\r",
      "Training batch 261\tloss: 2.8802\tacc: 0.2202\r",
      "Training batch 262\tloss: 2.8791\tacc: 0.2202\r",
      "Training batch 263\tloss: 2.8779\tacc: 0.2204\r",
      "Training batch 264\tloss: 2.8766\tacc: 0.2205\r",
      "Training batch 265\tloss: 2.8757\tacc: 0.2207\r",
      "Training batch 266\tloss: 2.8747\tacc: 0.2208\r",
      "Training batch 267\tloss: 2.8737\tacc: 0.2208\r",
      "Training batch 268\tloss: 2.8727\tacc: 0.2209\r",
      "Training batch 269\tloss: 2.8714\tacc: 0.2210\r",
      "Training batch 270\tloss: 2.8711\tacc: 0.2211\ttime: 70.276 s\n",
      "\r",
      "Validation batch 1\tloss: 2.4969\tacc: 0.2883\r",
      "Validation batch 2\tloss: 2.4997\tacc: 0.2826\r",
      "Validation batch 3\tloss: 2.4930\tacc: 0.2851\r",
      "Validation batch 4\tloss: 2.4983\tacc: 0.2802\r",
      "Validation batch 5\tloss: 2.5057\tacc: 0.2756\r",
      "Validation batch 6\tloss: 2.5020\tacc: 0.2731\r",
      "Validation batch 7\tloss: 2.5137\tacc: 0.2690\r",
      "Validation batch 8\tloss: 2.5068\tacc: 0.2697\r",
      "Validation batch 9\tloss: 2.5028\tacc: 0.2714\r",
      "Validation batch 10\tloss: 2.5120\tacc: 0.2698\r",
      "Validation batch 11\tloss: 2.5160\tacc: 0.2686\r",
      "Validation batch 12\tloss: 2.5156\tacc: 0.2691\r",
      "Validation batch 13\tloss: 2.5159\tacc: 0.2690\r",
      "Validation batch 14\tloss: 2.5162\tacc: 0.2688\r",
      "Validation batch 15\tloss: 2.5174\tacc: 0.2687\r",
      "Validation batch 16\tloss: 2.5164\tacc: 0.2686\r",
      "Validation batch 17\tloss: 2.5163\tacc: 0.2679\r",
      "Validation batch 18\tloss: 2.5174\tacc: 0.2679\r",
      "Validation batch 19\tloss: 2.5175\tacc: 0.2676\r",
      "Validation batch 20\tloss: 2.5164\tacc: 0.2675\r",
      "Validation batch 21\tloss: 2.5145\tacc: 0.2686\r",
      "Validation batch 22\tloss: 2.5150\tacc: 0.2688\r",
      "Validation batch 23\tloss: 2.5171\tacc: 0.2687\r",
      "Validation batch 24\tloss: 2.5175\tacc: 0.2688\r",
      "Validation batch 25\tloss: 2.5172\tacc: 0.2688\r",
      "Validation batch 26\tloss: 2.5161\tacc: 0.2696\r",
      "Validation batch 27\tloss: 2.5157\tacc: 0.2694\r",
      "Validation batch 28\tloss: 2.5168\tacc: 0.2692\r",
      "Validation batch 29\tloss: 2.5173\tacc: 0.2692\r",
      "Validation batch 30\tloss: 2.5191\tacc: 0.2690\r",
      "Validation batch 31\tloss: 2.5180\tacc: 0.2693\r",
      "Validation batch 32\tloss: 2.5187\tacc: 0.2689\r",
      "Validation batch 33\tloss: 2.5189\tacc: 0.2687\r",
      "Validation batch 34\tloss: 2.5194\tacc: 0.2686\r",
      "Validation batch 35\tloss: 2.5200\tacc: 0.2684\r",
      "Validation batch 36\tloss: 2.5213\tacc: 0.2679\r",
      "Validation batch 37\tloss: 2.5206\tacc: 0.2681\r",
      "Validation batch 38\tloss: 2.5201\tacc: 0.2681\r",
      "Validation batch 39\tloss: 2.5209\tacc: 0.2681\r",
      "Validation batch 40\tloss: 2.5213\tacc: 0.2679\r",
      "Validation batch 41\tloss: 2.5217\tacc: 0.2678\r",
      "Validation batch 42\tloss: 2.5221\tacc: 0.2676\r",
      "Validation batch 43\tloss: 2.5231\tacc: 0.2675\r",
      "Validation batch 44\tloss: 2.5233\tacc: 0.2677\r",
      "Validation batch 45\tloss: 2.5236\tacc: 0.2674\r",
      "Validation batch 46\tloss: 2.5229\tacc: 0.2674\r",
      "Validation batch 47\tloss: 2.5231\tacc: 0.2674\r",
      "Validation batch 48\tloss: 2.5226\tacc: 0.2676\r",
      "Validation batch 49\tloss: 2.5221\tacc: 0.2677\r",
      "Validation batch 50\tloss: 2.5224\tacc: 0.2676\r",
      "Validation batch 51\tloss: 2.5219\tacc: 0.2676\r",
      "Validation batch 52\tloss: 2.5218\tacc: 0.2677\r",
      "Validation batch 53\tloss: 2.5226\tacc: 0.2674\r",
      "Validation batch 54\tloss: 2.5236\tacc: 0.2671\r",
      "Validation batch 55\tloss: 2.5236\tacc: 0.2672\r",
      "Validation batch 56\tloss: 2.5227\tacc: 0.2676\r",
      "Validation batch 57\tloss: 2.5228\tacc: 0.2675\r",
      "Validation batch 58\tloss: 2.5227\tacc: 0.2674\r",
      "Validation batch 59\tloss: 2.5222\tacc: 0.2679\r",
      "Validation batch 60\tloss: 2.5217\tacc: 0.2682\r",
      "Validation batch 61\tloss: 2.5215\tacc: 0.2681\r",
      "Validation batch 62\tloss: 2.5217\tacc: 0.2680\r",
      "Validation batch 63\tloss: 2.5215\tacc: 0.2680\r",
      "Validation batch 64\tloss: 2.5221\tacc: 0.2676\r",
      "Validation batch 65\tloss: 2.5224\tacc: 0.2675\r",
      "Validation batch 66\tloss: 2.5227\tacc: 0.2676\r",
      "Validation batch 67\tloss: 2.5223\tacc: 0.2680\r",
      "Validation batch 68\tloss: 2.5223\tacc: 0.2681\r",
      "Validation batch 69\tloss: 2.5222\tacc: 0.2680\r",
      "Validation batch 70\tloss: 2.5229\tacc: 0.2678\r",
      "Validation batch 71\tloss: 2.5233\tacc: 0.2677\r",
      "Validation batch 72\tloss: 2.5237\tacc: 0.2676\r",
      "Validation batch 73\tloss: 2.5239\tacc: 0.2674\r",
      "Validation batch 74\tloss: 2.5237\tacc: 0.2675\r",
      "Validation batch 75\tloss: 2.5234\tacc: 0.2675\r",
      "Validation batch 76\tloss: 2.5234\tacc: 0.2675\r",
      "Validation batch 77\tloss: 2.5235\tacc: 0.2674\r",
      "Validation batch 78\tloss: 2.5237\tacc: 0.2676\r",
      "Validation batch 79\tloss: 2.5231\tacc: 0.2677\r",
      "Validation batch 80\tloss: 2.5234\tacc: 0.2676\r",
      "Validation batch 81\tloss: 2.5228\tacc: 0.2678\r",
      "Validation batch 82\tloss: 2.5232\tacc: 0.2675\r",
      "Validation batch 83\tloss: 2.5236\tacc: 0.2675\r",
      "Validation batch 84\tloss: 2.5234\tacc: 0.2675\r",
      "Validation batch 85\tloss: 2.5233\tacc: 0.2675\r",
      "Validation batch 86\tloss: 2.5237\tacc: 0.2675\r",
      "Validation batch 87\tloss: 2.5232\tacc: 0.2677\r",
      "Validation batch 88\tloss: 2.5233\tacc: 0.2676\r",
      "Validation batch 89\tloss: 2.5234\tacc: 0.2675\r",
      "Validation batch 90\tloss: 2.5238\tacc: 0.2673\ttime: 7.731 s\n",
      "The chkpt file has been updated at epoch 2.\n",
      "Epoch 3 of 5 \n",
      "\r",
      "Training batch 1\tloss: 2.5509\tacc: 0.2599\r",
      "Training batch 2\tloss: 2.5512\tacc: 0.2591\r",
      "Training batch 3\tloss: 2.5507\tacc: 0.2591\r",
      "Training batch 4\tloss: 2.5551\tacc: 0.2622\r",
      "Training batch 5\tloss: 2.5549\tacc: 0.2609\r",
      "Training batch 6\tloss: 2.5606\tacc: 0.2598\r",
      "Training batch 7\tloss: 2.5591\tacc: 0.2577\r",
      "Training batch 8\tloss: 2.5580\tacc: 0.2573\r",
      "Training batch 9\tloss: 2.5620\tacc: 0.2561\r",
      "Training batch 10\tloss: 2.5636\tacc: 0.2561\r",
      "Training batch 11\tloss: 2.5687\tacc: 0.2541\r",
      "Training batch 12\tloss: 2.5709\tacc: 0.2525\r",
      "Training batch 13\tloss: 2.5699\tacc: 0.2528\r",
      "Training batch 14\tloss: 2.5716\tacc: 0.2527\r",
      "Training batch 15\tloss: 2.5713\tacc: 0.2519\r",
      "Training batch 16\tloss: 2.5697\tacc: 0.2528\r",
      "Training batch 17\tloss: 2.5673\tacc: 0.2527\r",
      "Training batch 18\tloss: 2.5679\tacc: 0.2518\r",
      "Training batch 19\tloss: 2.5666\tacc: 0.2523\r",
      "Training batch 20\tloss: 2.5679\tacc: 0.2514\r",
      "Training batch 21\tloss: 2.5657\tacc: 0.2521\r",
      "Training batch 22\tloss: 2.5673\tacc: 0.2515\r",
      "Training batch 23\tloss: 2.5687\tacc: 0.2497\r",
      "Training batch 24\tloss: 2.5691\tacc: 0.2496\r",
      "Training batch 25\tloss: 2.5684\tacc: 0.2489\r",
      "Training batch 26\tloss: 2.5687\tacc: 0.2487\r",
      "Training batch 27\tloss: 2.5681\tacc: 0.2488\r",
      "Training batch 28\tloss: 2.5685\tacc: 0.2487\r",
      "Training batch 29\tloss: 2.5700\tacc: 0.2482\r",
      "Training batch 30\tloss: 2.5690\tacc: 0.2481\r",
      "Training batch 31\tloss: 2.5691\tacc: 0.2477\r",
      "Training batch 32\tloss: 2.5689\tacc: 0.2478\r",
      "Training batch 33\tloss: 2.5675\tacc: 0.2481\r",
      "Training batch 34\tloss: 2.5672\tacc: 0.2482\r",
      "Training batch 35\tloss: 2.5654\tacc: 0.2490\r",
      "Training batch 36\tloss: 2.5652\tacc: 0.2490\r",
      "Training batch 37\tloss: 2.5643\tacc: 0.2494\r",
      "Training batch 38\tloss: 2.5638\tacc: 0.2495\r",
      "Training batch 39\tloss: 2.5647\tacc: 0.2492\r",
      "Training batch 40\tloss: 2.5632\tacc: 0.2497\r",
      "Training batch 41\tloss: 2.5638\tacc: 0.2492\r",
      "Training batch 42\tloss: 2.5637\tacc: 0.2494\r",
      "Training batch 43\tloss: 2.5635\tacc: 0.2491\r",
      "Training batch 44\tloss: 2.5630\tacc: 0.2491\r",
      "Training batch 45\tloss: 2.5612\tacc: 0.2495\r",
      "Training batch 46\tloss: 2.5616\tacc: 0.2491\r",
      "Training batch 47\tloss: 2.5616\tacc: 0.2490\r",
      "Training batch 48\tloss: 2.5615\tacc: 0.2488\r",
      "Training batch 49\tloss: 2.5614\tacc: 0.2487\r",
      "Training batch 50\tloss: 2.5626\tacc: 0.2480\r",
      "Training batch 51\tloss: 2.5616\tacc: 0.2485\r",
      "Training batch 52\tloss: 2.5625\tacc: 0.2483\r",
      "Training batch 53\tloss: 2.5620\tacc: 0.2483\r",
      "Training batch 54\tloss: 2.5614\tacc: 0.2486\r",
      "Training batch 55\tloss: 2.5612\tacc: 0.2488\r",
      "Training batch 56\tloss: 2.5611\tacc: 0.2488\r",
      "Training batch 57\tloss: 2.5608\tacc: 0.2488\r",
      "Training batch 58\tloss: 2.5611\tacc: 0.2486\r",
      "Training batch 59\tloss: 2.5605\tacc: 0.2486\r",
      "Training batch 60\tloss: 2.5601\tacc: 0.2490\r",
      "Training batch 61\tloss: 2.5598\tacc: 0.2490\r",
      "Training batch 62\tloss: 2.5595\tacc: 0.2488\r",
      "Training batch 63\tloss: 2.5587\tacc: 0.2489\r",
      "Training batch 64\tloss: 2.5588\tacc: 0.2490\r",
      "Training batch 65\tloss: 2.5588\tacc: 0.2490\r",
      "Training batch 66\tloss: 2.5583\tacc: 0.2491\r",
      "Training batch 67\tloss: 2.5584\tacc: 0.2492\r",
      "Training batch 68\tloss: 2.5579\tacc: 0.2493\r",
      "Training batch 69\tloss: 2.5579\tacc: 0.2494\r",
      "Training batch 70\tloss: 2.5574\tacc: 0.2497\r",
      "Training batch 71\tloss: 2.5569\tacc: 0.2498\r",
      "Training batch 72\tloss: 2.5572\tacc: 0.2498\r",
      "Training batch 73\tloss: 2.5586\tacc: 0.2493\r",
      "Training batch 74\tloss: 2.5581\tacc: 0.2494\r",
      "Training batch 75\tloss: 2.5574\tacc: 0.2495\r",
      "Training batch 76\tloss: 2.5578\tacc: 0.2495\r",
      "Training batch 77\tloss: 2.5583\tacc: 0.2495\r",
      "Training batch 78\tloss: 2.5573\tacc: 0.2496\r",
      "Training batch 79\tloss: 2.5569\tacc: 0.2495\r",
      "Training batch 80\tloss: 2.5564\tacc: 0.2497\r",
      "Training batch 81\tloss: 2.5564\tacc: 0.2498\r",
      "Training batch 82\tloss: 2.5562\tacc: 0.2499\r",
      "Training batch 83\tloss: 2.5561\tacc: 0.2498\r",
      "Training batch 84\tloss: 2.5563\tacc: 0.2499\r",
      "Training batch 85\tloss: 2.5558\tacc: 0.2500\r",
      "Training batch 86\tloss: 2.5552\tacc: 0.2503\r",
      "Training batch 87\tloss: 2.5550\tacc: 0.2504\r",
      "Training batch 88\tloss: 2.5552\tacc: 0.2503\r",
      "Training batch 89\tloss: 2.5540\tacc: 0.2505\r",
      "Training batch 90\tloss: 2.5533\tacc: 0.2508\r",
      "Training batch 91\tloss: 2.5534\tacc: 0.2507\r",
      "Training batch 92\tloss: 2.5530\tacc: 0.2509\r",
      "Training batch 93\tloss: 2.5529\tacc: 0.2508\r",
      "Training batch 94\tloss: 2.5528\tacc: 0.2508\r",
      "Training batch 95\tloss: 2.5521\tacc: 0.2510\r",
      "Training batch 96\tloss: 2.5521\tacc: 0.2510\r",
      "Training batch 97\tloss: 2.5521\tacc: 0.2511\r",
      "Training batch 98\tloss: 2.5518\tacc: 0.2512\r",
      "Training batch 99\tloss: 2.5516\tacc: 0.2511\r",
      "Training batch 100\tloss: 2.5515\tacc: 0.2510\r",
      "Training batch 101\tloss: 2.5511\tacc: 0.2511\r",
      "Training batch 102\tloss: 2.5511\tacc: 0.2511\r",
      "Training batch 103\tloss: 2.5509\tacc: 0.2511\r",
      "Training batch 104\tloss: 2.5505\tacc: 0.2512\r",
      "Training batch 105\tloss: 2.5500\tacc: 0.2513\r",
      "Training batch 106\tloss: 2.5502\tacc: 0.2513\r",
      "Training batch 107\tloss: 2.5499\tacc: 0.2514\r",
      "Training batch 108\tloss: 2.5494\tacc: 0.2515\r",
      "Training batch 109\tloss: 2.5490\tacc: 0.2515\r",
      "Training batch 110\tloss: 2.5488\tacc: 0.2515\r",
      "Training batch 111\tloss: 2.5491\tacc: 0.2514\r",
      "Training batch 112\tloss: 2.5487\tacc: 0.2515\r",
      "Training batch 113\tloss: 2.5486\tacc: 0.2516\r",
      "Training batch 114\tloss: 2.5485\tacc: 0.2516\r",
      "Training batch 115\tloss: 2.5481\tacc: 0.2517\r",
      "Training batch 116\tloss: 2.5481\tacc: 0.2516\r",
      "Training batch 117\tloss: 2.5474\tacc: 0.2517\r",
      "Training batch 118\tloss: 2.5471\tacc: 0.2519\r",
      "Training batch 119\tloss: 2.5468\tacc: 0.2521\r",
      "Training batch 120\tloss: 2.5465\tacc: 0.2522\r",
      "Training batch 121\tloss: 2.5464\tacc: 0.2522\r",
      "Training batch 122\tloss: 2.5461\tacc: 0.2522\r",
      "Training batch 123\tloss: 2.5461\tacc: 0.2523\r",
      "Training batch 124\tloss: 2.5460\tacc: 0.2523\r",
      "Training batch 125\tloss: 2.5457\tacc: 0.2523\r",
      "Training batch 126\tloss: 2.5453\tacc: 0.2524\r",
      "Training batch 127\tloss: 2.5451\tacc: 0.2525\r",
      "Training batch 128\tloss: 2.5454\tacc: 0.2524\r",
      "Training batch 129\tloss: 2.5455\tacc: 0.2523\r",
      "Training batch 130\tloss: 2.5451\tacc: 0.2524\r",
      "Training batch 131\tloss: 2.5449\tacc: 0.2525\r",
      "Training batch 132\tloss: 2.5450\tacc: 0.2526\r",
      "Training batch 133\tloss: 2.5447\tacc: 0.2525\r",
      "Training batch 134\tloss: 2.5449\tacc: 0.2524\r",
      "Training batch 135\tloss: 2.5450\tacc: 0.2524\r",
      "Training batch 136\tloss: 2.5448\tacc: 0.2524\r",
      "Training batch 137\tloss: 2.5447\tacc: 0.2524\r",
      "Training batch 138\tloss: 2.5448\tacc: 0.2524\r",
      "Training batch 139\tloss: 2.5445\tacc: 0.2524\r",
      "Training batch 140\tloss: 2.5445\tacc: 0.2524\r",
      "Training batch 141\tloss: 2.5443\tacc: 0.2525\r",
      "Training batch 142\tloss: 2.5439\tacc: 0.2526\r",
      "Training batch 143\tloss: 2.5435\tacc: 0.2526\r",
      "Training batch 144\tloss: 2.5435\tacc: 0.2525\r",
      "Training batch 145\tloss: 2.5435\tacc: 0.2526\r",
      "Training batch 146\tloss: 2.5435\tacc: 0.2526\r",
      "Training batch 147\tloss: 2.5433\tacc: 0.2526\r",
      "Training batch 148\tloss: 2.5427\tacc: 0.2527\r",
      "Training batch 149\tloss: 2.5424\tacc: 0.2528\r",
      "Training batch 150\tloss: 2.5422\tacc: 0.2529\r",
      "Training batch 151\tloss: 2.5421\tacc: 0.2529\r",
      "Training batch 152\tloss: 2.5420\tacc: 0.2530\r",
      "Training batch 153\tloss: 2.5420\tacc: 0.2530\r",
      "Training batch 154\tloss: 2.5423\tacc: 0.2530\r",
      "Training batch 155\tloss: 2.5420\tacc: 0.2531\r",
      "Training batch 156\tloss: 2.5419\tacc: 0.2530\r",
      "Training batch 157\tloss: 2.5416\tacc: 0.2531\r",
      "Training batch 158\tloss: 2.5415\tacc: 0.2531\r",
      "Training batch 159\tloss: 2.5415\tacc: 0.2530\r",
      "Training batch 160\tloss: 2.5413\tacc: 0.2531\r",
      "Training batch 161\tloss: 2.5414\tacc: 0.2530\r",
      "Training batch 162\tloss: 2.5414\tacc: 0.2531\r",
      "Training batch 163\tloss: 2.5413\tacc: 0.2532\r",
      "Training batch 164\tloss: 2.5413\tacc: 0.2531\r",
      "Training batch 165\tloss: 2.5411\tacc: 0.2532\r",
      "Training batch 166\tloss: 2.5408\tacc: 0.2532\r",
      "Training batch 167\tloss: 2.5406\tacc: 0.2533\r",
      "Training batch 168\tloss: 2.5401\tacc: 0.2534\r",
      "Training batch 169\tloss: 2.5398\tacc: 0.2536\r",
      "Training batch 170\tloss: 2.5398\tacc: 0.2536\r",
      "Training batch 171\tloss: 2.5400\tacc: 0.2536\r",
      "Training batch 172\tloss: 2.5398\tacc: 0.2536\r",
      "Training batch 173\tloss: 2.5396\tacc: 0.2537\r",
      "Training batch 174\tloss: 2.5398\tacc: 0.2536\r",
      "Training batch 175\tloss: 2.5394\tacc: 0.2537\r",
      "Training batch 176\tloss: 2.5396\tacc: 0.2537\r",
      "Training batch 177\tloss: 2.5395\tacc: 0.2538\r",
      "Training batch 178\tloss: 2.5392\tacc: 0.2538\r",
      "Training batch 179\tloss: 2.5391\tacc: 0.2538\r",
      "Training batch 180\tloss: 2.5387\tacc: 0.2539\r",
      "Training batch 181\tloss: 2.5385\tacc: 0.2540\r",
      "Training batch 182\tloss: 2.5383\tacc: 0.2541\r",
      "Training batch 183\tloss: 2.5383\tacc: 0.2541\r",
      "Training batch 184\tloss: 2.5382\tacc: 0.2541\r",
      "Training batch 185\tloss: 2.5381\tacc: 0.2542\r",
      "Training batch 186\tloss: 2.5382\tacc: 0.2541\r",
      "Training batch 187\tloss: 2.5380\tacc: 0.2542\r",
      "Training batch 188\tloss: 2.5378\tacc: 0.2543\r",
      "Training batch 189\tloss: 2.5378\tacc: 0.2543\r",
      "Training batch 190\tloss: 2.5378\tacc: 0.2543\r",
      "Training batch 191\tloss: 2.5382\tacc: 0.2542\r",
      "Training batch 192\tloss: 2.5379\tacc: 0.2542\r",
      "Training batch 193\tloss: 2.5376\tacc: 0.2544\r",
      "Training batch 194\tloss: 2.5373\tacc: 0.2544\r",
      "Training batch 195\tloss: 2.5373\tacc: 0.2544\r",
      "Training batch 196\tloss: 2.5371\tacc: 0.2545\r",
      "Training batch 197\tloss: 2.5368\tacc: 0.2546\r",
      "Training batch 198\tloss: 2.5366\tacc: 0.2547\r",
      "Training batch 199\tloss: 2.5365\tacc: 0.2547\r",
      "Training batch 200\tloss: 2.5362\tacc: 0.2547\r",
      "Training batch 201\tloss: 2.5366\tacc: 0.2546\r",
      "Training batch 202\tloss: 2.5364\tacc: 0.2547\r",
      "Training batch 203\tloss: 2.5360\tacc: 0.2548\r",
      "Training batch 204\tloss: 2.5356\tacc: 0.2549\r",
      "Training batch 205\tloss: 2.5353\tacc: 0.2551\r",
      "Training batch 206\tloss: 2.5353\tacc: 0.2550\r",
      "Training batch 207\tloss: 2.5351\tacc: 0.2551\r",
      "Training batch 208\tloss: 2.5348\tacc: 0.2552\r",
      "Training batch 209\tloss: 2.5349\tacc: 0.2551\r",
      "Training batch 210\tloss: 2.5347\tacc: 0.2552\r",
      "Training batch 211\tloss: 2.5347\tacc: 0.2552\r",
      "Training batch 212\tloss: 2.5347\tacc: 0.2552\r",
      "Training batch 213\tloss: 2.5344\tacc: 0.2553\r",
      "Training batch 214\tloss: 2.5342\tacc: 0.2554\r",
      "Training batch 215\tloss: 2.5339\tacc: 0.2555\r",
      "Training batch 216\tloss: 2.5337\tacc: 0.2556\r",
      "Training batch 217\tloss: 2.5335\tacc: 0.2557\r",
      "Training batch 218\tloss: 2.5333\tacc: 0.2557\r",
      "Training batch 219\tloss: 2.5334\tacc: 0.2557\r",
      "Training batch 220\tloss: 2.5332\tacc: 0.2557\r",
      "Training batch 221\tloss: 2.5330\tacc: 0.2558\r",
      "Training batch 222\tloss: 2.5330\tacc: 0.2558\r",
      "Training batch 223\tloss: 2.5328\tacc: 0.2559\r",
      "Training batch 224\tloss: 2.5327\tacc: 0.2559\r",
      "Training batch 225\tloss: 2.5325\tacc: 0.2560\r",
      "Training batch 226\tloss: 2.5323\tacc: 0.2560\r",
      "Training batch 227\tloss: 2.5322\tacc: 0.2560\r",
      "Training batch 228\tloss: 2.5324\tacc: 0.2559\r",
      "Training batch 229\tloss: 2.5323\tacc: 0.2559\r",
      "Training batch 230\tloss: 2.5320\tacc: 0.2560\r",
      "Training batch 231\tloss: 2.5317\tacc: 0.2560\r",
      "Training batch 232\tloss: 2.5316\tacc: 0.2560\r",
      "Training batch 233\tloss: 2.5315\tacc: 0.2560\r",
      "Training batch 234\tloss: 2.5316\tacc: 0.2560\r",
      "Training batch 235\tloss: 2.5312\tacc: 0.2561\r",
      "Training batch 236\tloss: 2.5311\tacc: 0.2561\r",
      "Training batch 237\tloss: 2.5311\tacc: 0.2561\r",
      "Training batch 238\tloss: 2.5310\tacc: 0.2561\r",
      "Training batch 239\tloss: 2.5308\tacc: 0.2562\r",
      "Training batch 240\tloss: 2.5306\tacc: 0.2563\r",
      "Training batch 241\tloss: 2.5308\tacc: 0.2563\r",
      "Training batch 242\tloss: 2.5305\tacc: 0.2564\r",
      "Training batch 243\tloss: 2.5302\tacc: 0.2564\r",
      "Training batch 244\tloss: 2.5297\tacc: 0.2566\r",
      "Training batch 245\tloss: 2.5297\tacc: 0.2565\r",
      "Training batch 246\tloss: 2.5294\tacc: 0.2566\r",
      "Training batch 247\tloss: 2.5293\tacc: 0.2566\r",
      "Training batch 248\tloss: 2.5291\tacc: 0.2567\r",
      "Training batch 249\tloss: 2.5289\tacc: 0.2568\r",
      "Training batch 250\tloss: 2.5286\tacc: 0.2569\r",
      "Training batch 251\tloss: 2.5285\tacc: 0.2569\r",
      "Training batch 252\tloss: 2.5283\tacc: 0.2569\r",
      "Training batch 253\tloss: 2.5281\tacc: 0.2569\r",
      "Training batch 254\tloss: 2.5279\tacc: 0.2570\r",
      "Training batch 255\tloss: 2.5278\tacc: 0.2570\r",
      "Training batch 256\tloss: 2.5276\tacc: 0.2570\r",
      "Training batch 257\tloss: 2.5275\tacc: 0.2571\r",
      "Training batch 258\tloss: 2.5273\tacc: 0.2571\r",
      "Training batch 259\tloss: 2.5271\tacc: 0.2572\r",
      "Training batch 260\tloss: 2.5268\tacc: 0.2573\r",
      "Training batch 261\tloss: 2.5267\tacc: 0.2573\r",
      "Training batch 262\tloss: 2.5265\tacc: 0.2574\r",
      "Training batch 263\tloss: 2.5262\tacc: 0.2575\r",
      "Training batch 264\tloss: 2.5260\tacc: 0.2575\r",
      "Training batch 265\tloss: 2.5258\tacc: 0.2576\r",
      "Training batch 266\tloss: 2.5254\tacc: 0.2577\r",
      "Training batch 267\tloss: 2.5253\tacc: 0.2577\r",
      "Training batch 268\tloss: 2.5254\tacc: 0.2577\r",
      "Training batch 269\tloss: 2.5253\tacc: 0.2578\r",
      "Training batch 270\tloss: 2.5251\tacc: 0.2578\ttime: 70.159 s\n",
      "\r",
      "Validation batch 1\tloss: 2.4142\tacc: 0.2972\r",
      "Validation batch 2\tloss: 2.4193\tacc: 0.2875\r",
      "Validation batch 3\tloss: 2.4117\tacc: 0.2899\r",
      "Validation batch 4\tloss: 2.4206\tacc: 0.2861\r",
      "Validation batch 5\tloss: 2.4281\tacc: 0.2822\r",
      "Validation batch 6\tloss: 2.4242\tacc: 0.2804\r",
      "Validation batch 7\tloss: 2.4371\tacc: 0.2767\r",
      "Validation batch 8\tloss: 2.4295\tacc: 0.2787\r",
      "Validation batch 9\tloss: 2.4251\tacc: 0.2806\r",
      "Validation batch 10\tloss: 2.4346\tacc: 0.2784\r",
      "Validation batch 11\tloss: 2.4382\tacc: 0.2771\r",
      "Validation batch 12\tloss: 2.4373\tacc: 0.2778\r",
      "Validation batch 13\tloss: 2.4379\tacc: 0.2776\r",
      "Validation batch 14\tloss: 2.4381\tacc: 0.2775\r",
      "Validation batch 15\tloss: 2.4399\tacc: 0.2771\r",
      "Validation batch 16\tloss: 2.4385\tacc: 0.2770\r",
      "Validation batch 17\tloss: 2.4379\tacc: 0.2771\r",
      "Validation batch 18\tloss: 2.4386\tacc: 0.2773\r",
      "Validation batch 19\tloss: 2.4388\tacc: 0.2775\r",
      "Validation batch 20\tloss: 2.4382\tacc: 0.2771\r",
      "Validation batch 21\tloss: 2.4366\tacc: 0.2781\r",
      "Validation batch 22\tloss: 2.4368\tacc: 0.2782\r",
      "Validation batch 23\tloss: 2.4392\tacc: 0.2781\r",
      "Validation batch 24\tloss: 2.4394\tacc: 0.2780\r",
      "Validation batch 25\tloss: 2.4394\tacc: 0.2778\r",
      "Validation batch 26\tloss: 2.4384\tacc: 0.2785\r",
      "Validation batch 27\tloss: 2.4381\tacc: 0.2780\r",
      "Validation batch 28\tloss: 2.4389\tacc: 0.2779\r",
      "Validation batch 29\tloss: 2.4391\tacc: 0.2780\r",
      "Validation batch 30\tloss: 2.4410\tacc: 0.2777\r",
      "Validation batch 31\tloss: 2.4399\tacc: 0.2779\r",
      "Validation batch 32\tloss: 2.4407\tacc: 0.2775\r",
      "Validation batch 33\tloss: 2.4408\tacc: 0.2775\r",
      "Validation batch 34\tloss: 2.4412\tacc: 0.2774\r",
      "Validation batch 35\tloss: 2.4419\tacc: 0.2772\r",
      "Validation batch 36\tloss: 2.4432\tacc: 0.2768\r",
      "Validation batch 37\tloss: 2.4424\tacc: 0.2773\r",
      "Validation batch 38\tloss: 2.4421\tacc: 0.2774\r",
      "Validation batch 39\tloss: 2.4430\tacc: 0.2772\r",
      "Validation batch 40\tloss: 2.4436\tacc: 0.2769\r",
      "Validation batch 41\tloss: 2.4441\tacc: 0.2769\r",
      "Validation batch 42\tloss: 2.4445\tacc: 0.2769\r",
      "Validation batch 43\tloss: 2.4456\tacc: 0.2769\r",
      "Validation batch 44\tloss: 2.4460\tacc: 0.2770\r",
      "Validation batch 45\tloss: 2.4463\tacc: 0.2767\r",
      "Validation batch 46\tloss: 2.4454\tacc: 0.2768\r",
      "Validation batch 47\tloss: 2.4454\tacc: 0.2770\r",
      "Validation batch 48\tloss: 2.4448\tacc: 0.2772\r",
      "Validation batch 49\tloss: 2.4442\tacc: 0.2776\r",
      "Validation batch 50\tloss: 2.4445\tacc: 0.2775\r",
      "Validation batch 51\tloss: 2.4439\tacc: 0.2774\r",
      "Validation batch 52\tloss: 2.4438\tacc: 0.2776\r",
      "Validation batch 53\tloss: 2.4446\tacc: 0.2772\r",
      "Validation batch 54\tloss: 2.4457\tacc: 0.2772\r",
      "Validation batch 55\tloss: 2.4457\tacc: 0.2773\r",
      "Validation batch 56\tloss: 2.4448\tacc: 0.2776\r",
      "Validation batch 57\tloss: 2.4449\tacc: 0.2776\r",
      "Validation batch 58\tloss: 2.4448\tacc: 0.2777\r",
      "Validation batch 59\tloss: 2.4444\tacc: 0.2781\r",
      "Validation batch 60\tloss: 2.4440\tacc: 0.2784\r",
      "Validation batch 61\tloss: 2.4438\tacc: 0.2783\r",
      "Validation batch 62\tloss: 2.4440\tacc: 0.2782\r",
      "Validation batch 63\tloss: 2.4437\tacc: 0.2781\r",
      "Validation batch 64\tloss: 2.4444\tacc: 0.2778\r",
      "Validation batch 65\tloss: 2.4446\tacc: 0.2778\r",
      "Validation batch 66\tloss: 2.4449\tacc: 0.2778\r",
      "Validation batch 67\tloss: 2.4446\tacc: 0.2781\r",
      "Validation batch 68\tloss: 2.4445\tacc: 0.2782\r",
      "Validation batch 69\tloss: 2.4446\tacc: 0.2781\r",
      "Validation batch 70\tloss: 2.4453\tacc: 0.2780\r",
      "Validation batch 71\tloss: 2.4457\tacc: 0.2779\r",
      "Validation batch 72\tloss: 2.4463\tacc: 0.2779\r",
      "Validation batch 73\tloss: 2.4463\tacc: 0.2778\r",
      "Validation batch 74\tloss: 2.4461\tacc: 0.2778\r",
      "Validation batch 75\tloss: 2.4458\tacc: 0.2780\r",
      "Validation batch 76\tloss: 2.4457\tacc: 0.2781\r",
      "Validation batch 77\tloss: 2.4460\tacc: 0.2780\r",
      "Validation batch 78\tloss: 2.4462\tacc: 0.2781\r",
      "Validation batch 79\tloss: 2.4456\tacc: 0.2783\r",
      "Validation batch 80\tloss: 2.4458\tacc: 0.2782\r",
      "Validation batch 81\tloss: 2.4452\tacc: 0.2783\r",
      "Validation batch 82\tloss: 2.4456\tacc: 0.2781\r",
      "Validation batch 83\tloss: 2.4460\tacc: 0.2782\r",
      "Validation batch 84\tloss: 2.4457\tacc: 0.2782\r",
      "Validation batch 85\tloss: 2.4455\tacc: 0.2782\r",
      "Validation batch 86\tloss: 2.4459\tacc: 0.2782\r",
      "Validation batch 87\tloss: 2.4454\tacc: 0.2783\r",
      "Validation batch 88\tloss: 2.4454\tacc: 0.2782\r",
      "Validation batch 89\tloss: 2.4455\tacc: 0.2783\r",
      "Validation batch 90\tloss: 2.4459\tacc: 0.2781\ttime: 7.755 s\n",
      "The chkpt file has been updated at epoch 3.\n",
      "Epoch 4 of 5 \n",
      "\r",
      "Training batch 1\tloss: 2.4458\tacc: 0.2837\r",
      "Training batch 2\tloss: 2.4976\tacc: 0.2677\r",
      "Training batch 3\tloss: 2.4822\tacc: 0.2722\r",
      "Training batch 4\tloss: 2.4883\tacc: 0.2710\r",
      "Training batch 5\tloss: 2.4973\tacc: 0.2684\r",
      "Training batch 6\tloss: 2.5055\tacc: 0.2653\r",
      "Training batch 7\tloss: 2.5043\tacc: 0.2642\r",
      "Training batch 8\tloss: 2.5039\tacc: 0.2638\r",
      "Training batch 9\tloss: 2.4972\tacc: 0.2658\r",
      "Training batch 10\tloss: 2.4998\tacc: 0.2628\r",
      "Training batch 11\tloss: 2.4993\tacc: 0.2625\r",
      "Training batch 12\tloss: 2.4930\tacc: 0.2644\r",
      "Training batch 13\tloss: 2.4946\tacc: 0.2635\r",
      "Training batch 14\tloss: 2.4950\tacc: 0.2629\r",
      "Training batch 15\tloss: 2.4946\tacc: 0.2631\r",
      "Training batch 16\tloss: 2.4928\tacc: 0.2641\r",
      "Training batch 17\tloss: 2.4937\tacc: 0.2645\r",
      "Training batch 18\tloss: 2.4915\tacc: 0.2651\r",
      "Training batch 19\tloss: 2.4908\tacc: 0.2659\r",
      "Training batch 20\tloss: 2.4916\tacc: 0.2659\r",
      "Training batch 21\tloss: 2.4899\tacc: 0.2671\r",
      "Training batch 22\tloss: 2.4871\tacc: 0.2687\r",
      "Training batch 23\tloss: 2.4890\tacc: 0.2680\r",
      "Training batch 24\tloss: 2.4907\tacc: 0.2676\r",
      "Training batch 25\tloss: 2.4908\tacc: 0.2677\r",
      "Training batch 26\tloss: 2.4901\tacc: 0.2675\r",
      "Training batch 27\tloss: 2.4905\tacc: 0.2675\r",
      "Training batch 28\tloss: 2.4919\tacc: 0.2668\r",
      "Training batch 29\tloss: 2.4929\tacc: 0.2666\r",
      "Training batch 30\tloss: 2.4929\tacc: 0.2668\r",
      "Training batch 31\tloss: 2.4920\tacc: 0.2669\r",
      "Training batch 32\tloss: 2.4897\tacc: 0.2675\r",
      "Training batch 33\tloss: 2.4884\tacc: 0.2679\r",
      "Training batch 34\tloss: 2.4883\tacc: 0.2677\r",
      "Training batch 35\tloss: 2.4876\tacc: 0.2679\r",
      "Training batch 36\tloss: 2.4872\tacc: 0.2679\r",
      "Training batch 37\tloss: 2.4888\tacc: 0.2679\r",
      "Training batch 38\tloss: 2.4881\tacc: 0.2681\r",
      "Training batch 39\tloss: 2.4870\tacc: 0.2684\r",
      "Training batch 40\tloss: 2.4880\tacc: 0.2685\r",
      "Training batch 41\tloss: 2.4870\tacc: 0.2685\r",
      "Training batch 42\tloss: 2.4869\tacc: 0.2686\r",
      "Training batch 43\tloss: 2.4859\tacc: 0.2689\r",
      "Training batch 44\tloss: 2.4855\tacc: 0.2690\r",
      "Training batch 45\tloss: 2.4848\tacc: 0.2691\r",
      "Training batch 46\tloss: 2.4846\tacc: 0.2691\r",
      "Training batch 47\tloss: 2.4846\tacc: 0.2691\r",
      "Training batch 48\tloss: 2.4845\tacc: 0.2693\r",
      "Training batch 49\tloss: 2.4846\tacc: 0.2694\r",
      "Training batch 50\tloss: 2.4854\tacc: 0.2689\r",
      "Training batch 51\tloss: 2.4858\tacc: 0.2686\r",
      "Training batch 52\tloss: 2.4858\tacc: 0.2686\r",
      "Training batch 53\tloss: 2.4866\tacc: 0.2683\r",
      "Training batch 54\tloss: 2.4867\tacc: 0.2681\r",
      "Training batch 55\tloss: 2.4865\tacc: 0.2681\r",
      "Training batch 56\tloss: 2.4854\tacc: 0.2686\r",
      "Training batch 57\tloss: 2.4845\tacc: 0.2687\r",
      "Training batch 58\tloss: 2.4830\tacc: 0.2691\r",
      "Training batch 59\tloss: 2.4827\tacc: 0.2688\r",
      "Training batch 60\tloss: 2.4827\tacc: 0.2689\r",
      "Training batch 61\tloss: 2.4822\tacc: 0.2689\r",
      "Training batch 62\tloss: 2.4820\tacc: 0.2690\r",
      "Training batch 63\tloss: 2.4814\tacc: 0.2690\r",
      "Training batch 64\tloss: 2.4822\tacc: 0.2686\r",
      "Training batch 65\tloss: 2.4821\tacc: 0.2687\r",
      "Training batch 66\tloss: 2.4817\tacc: 0.2686\r",
      "Training batch 67\tloss: 2.4817\tacc: 0.2685\r",
      "Training batch 68\tloss: 2.4824\tacc: 0.2682\r",
      "Training batch 69\tloss: 2.4824\tacc: 0.2682\r",
      "Training batch 70\tloss: 2.4831\tacc: 0.2678\r",
      "Training batch 71\tloss: 2.4826\tacc: 0.2679\r",
      "Training batch 72\tloss: 2.4824\tacc: 0.2679\r",
      "Training batch 73\tloss: 2.4825\tacc: 0.2678\r",
      "Training batch 74\tloss: 2.4826\tacc: 0.2678\r",
      "Training batch 75\tloss: 2.4821\tacc: 0.2680\r",
      "Training batch 76\tloss: 2.4814\tacc: 0.2682\r",
      "Training batch 77\tloss: 2.4814\tacc: 0.2684\r",
      "Training batch 78\tloss: 2.4816\tacc: 0.2682\r",
      "Training batch 79\tloss: 2.4814\tacc: 0.2683\r",
      "Training batch 80\tloss: 2.4811\tacc: 0.2683\r",
      "Training batch 81\tloss: 2.4812\tacc: 0.2684\r",
      "Training batch 82\tloss: 2.4813\tacc: 0.2684\r",
      "Training batch 83\tloss: 2.4806\tacc: 0.2685\r",
      "Training batch 84\tloss: 2.4804\tacc: 0.2684\r",
      "Training batch 85\tloss: 2.4803\tacc: 0.2684\r",
      "Training batch 86\tloss: 2.4806\tacc: 0.2682\r",
      "Training batch 87\tloss: 2.4806\tacc: 0.2683\r",
      "Training batch 88\tloss: 2.4799\tacc: 0.2685\r",
      "Training batch 89\tloss: 2.4801\tacc: 0.2684\r",
      "Training batch 90\tloss: 2.4795\tacc: 0.2684\r",
      "Training batch 91\tloss: 2.4795\tacc: 0.2684\r",
      "Training batch 92\tloss: 2.4796\tacc: 0.2682\r",
      "Training batch 93\tloss: 2.4790\tacc: 0.2683\r",
      "Training batch 94\tloss: 2.4788\tacc: 0.2682\r",
      "Training batch 95\tloss: 2.4790\tacc: 0.2681\r",
      "Training batch 96\tloss: 2.4791\tacc: 0.2680\r",
      "Training batch 97\tloss: 2.4790\tacc: 0.2679\r",
      "Training batch 98\tloss: 2.4782\tacc: 0.2682\r",
      "Training batch 99\tloss: 2.4783\tacc: 0.2683\r",
      "Training batch 100\tloss: 2.4781\tacc: 0.2683\r",
      "Training batch 101\tloss: 2.4780\tacc: 0.2682\r",
      "Training batch 102\tloss: 2.4782\tacc: 0.2682\r",
      "Training batch 103\tloss: 2.4781\tacc: 0.2682\r",
      "Training batch 104\tloss: 2.4784\tacc: 0.2681\r",
      "Training batch 105\tloss: 2.4780\tacc: 0.2682\r",
      "Training batch 106\tloss: 2.4783\tacc: 0.2680\r",
      "Training batch 107\tloss: 2.4782\tacc: 0.2680\r",
      "Training batch 108\tloss: 2.4781\tacc: 0.2680\r",
      "Training batch 109\tloss: 2.4779\tacc: 0.2682\r",
      "Training batch 110\tloss: 2.4774\tacc: 0.2685\r",
      "Training batch 111\tloss: 2.4770\tacc: 0.2685\r",
      "Training batch 112\tloss: 2.4774\tacc: 0.2683\r",
      "Training batch 113\tloss: 2.4773\tacc: 0.2684\r",
      "Training batch 114\tloss: 2.4771\tacc: 0.2685\r",
      "Training batch 115\tloss: 2.4776\tacc: 0.2684\r",
      "Training batch 116\tloss: 2.4780\tacc: 0.2683\r",
      "Training batch 117\tloss: 2.4777\tacc: 0.2684\r",
      "Training batch 118\tloss: 2.4774\tacc: 0.2684\r",
      "Training batch 119\tloss: 2.4770\tacc: 0.2685\r",
      "Training batch 120\tloss: 2.4767\tacc: 0.2686\r",
      "Training batch 121\tloss: 2.4764\tacc: 0.2686\r",
      "Training batch 122\tloss: 2.4762\tacc: 0.2687\r",
      "Training batch 123\tloss: 2.4756\tacc: 0.2688\r",
      "Training batch 124\tloss: 2.4754\tacc: 0.2688\r",
      "Training batch 125\tloss: 2.4752\tacc: 0.2687\r",
      "Training batch 126\tloss: 2.4749\tacc: 0.2688\r",
      "Training batch 127\tloss: 2.4748\tacc: 0.2687\r",
      "Training batch 128\tloss: 2.4749\tacc: 0.2687\r",
      "Training batch 129\tloss: 2.4747\tacc: 0.2687\r",
      "Training batch 130\tloss: 2.4744\tacc: 0.2688\r",
      "Training batch 131\tloss: 2.4741\tacc: 0.2689\r",
      "Training batch 132\tloss: 2.4742\tacc: 0.2689\r",
      "Training batch 133\tloss: 2.4742\tacc: 0.2689\r",
      "Training batch 134\tloss: 2.4742\tacc: 0.2689\r",
      "Training batch 135\tloss: 2.4742\tacc: 0.2689\r",
      "Training batch 136\tloss: 2.4741\tacc: 0.2689\r",
      "Training batch 137\tloss: 2.4739\tacc: 0.2690\r",
      "Training batch 138\tloss: 2.4739\tacc: 0.2690\r",
      "Training batch 139\tloss: 2.4740\tacc: 0.2690\r",
      "Training batch 140\tloss: 2.4741\tacc: 0.2689\r",
      "Training batch 141\tloss: 2.4739\tacc: 0.2688\r",
      "Training batch 142\tloss: 2.4741\tacc: 0.2687\r",
      "Training batch 143\tloss: 2.4741\tacc: 0.2686\r",
      "Training batch 144\tloss: 2.4738\tacc: 0.2687\r",
      "Training batch 145\tloss: 2.4738\tacc: 0.2687\r",
      "Training batch 146\tloss: 2.4740\tacc: 0.2686\r",
      "Training batch 147\tloss: 2.4735\tacc: 0.2688\r",
      "Training batch 148\tloss: 2.4730\tacc: 0.2689\r",
      "Training batch 149\tloss: 2.4730\tacc: 0.2687\r",
      "Training batch 150\tloss: 2.4729\tacc: 0.2688\r",
      "Training batch 151\tloss: 2.4732\tacc: 0.2687\r",
      "Training batch 152\tloss: 2.4728\tacc: 0.2687\r",
      "Training batch 153\tloss: 2.4731\tacc: 0.2685\r",
      "Training batch 154\tloss: 2.4729\tacc: 0.2685\r",
      "Training batch 155\tloss: 2.4730\tacc: 0.2685\r",
      "Training batch 156\tloss: 2.4730\tacc: 0.2686\r",
      "Training batch 157\tloss: 2.4727\tacc: 0.2686\r",
      "Training batch 158\tloss: 2.4724\tacc: 0.2686\r",
      "Training batch 159\tloss: 2.4722\tacc: 0.2686\r",
      "Training batch 160\tloss: 2.4725\tacc: 0.2685\r",
      "Training batch 161\tloss: 2.4722\tacc: 0.2686\r",
      "Training batch 162\tloss: 2.4720\tacc: 0.2686\r",
      "Training batch 163\tloss: 2.4718\tacc: 0.2685\r",
      "Training batch 164\tloss: 2.4716\tacc: 0.2686\r",
      "Training batch 165\tloss: 2.4714\tacc: 0.2686\r",
      "Training batch 166\tloss: 2.4713\tacc: 0.2686\r",
      "Training batch 167\tloss: 2.4712\tacc: 0.2686\r",
      "Training batch 168\tloss: 2.4715\tacc: 0.2685\r",
      "Training batch 169\tloss: 2.4712\tacc: 0.2686\r",
      "Training batch 170\tloss: 2.4713\tacc: 0.2686\r",
      "Training batch 171\tloss: 2.4713\tacc: 0.2686\r",
      "Training batch 172\tloss: 2.4711\tacc: 0.2688\r",
      "Training batch 173\tloss: 2.4712\tacc: 0.2687\r",
      "Training batch 174\tloss: 2.4712\tacc: 0.2687\r",
      "Training batch 175\tloss: 2.4713\tacc: 0.2688\r",
      "Training batch 176\tloss: 2.4711\tacc: 0.2688\r",
      "Training batch 177\tloss: 2.4712\tacc: 0.2688\r",
      "Training batch 178\tloss: 2.4707\tacc: 0.2688\r",
      "Training batch 179\tloss: 2.4707\tacc: 0.2688\r",
      "Training batch 180\tloss: 2.4709\tacc: 0.2687\r",
      "Training batch 181\tloss: 2.4708\tacc: 0.2687\r",
      "Training batch 182\tloss: 2.4706\tacc: 0.2687\r",
      "Training batch 183\tloss: 2.4704\tacc: 0.2687\r",
      "Training batch 184\tloss: 2.4701\tacc: 0.2688\r",
      "Training batch 185\tloss: 2.4701\tacc: 0.2688\r",
      "Training batch 186\tloss: 2.4701\tacc: 0.2689\r",
      "Training batch 187\tloss: 2.4700\tacc: 0.2689\r",
      "Training batch 188\tloss: 2.4699\tacc: 0.2689\r",
      "Training batch 189\tloss: 2.4700\tacc: 0.2689\r",
      "Training batch 190\tloss: 2.4699\tacc: 0.2689\r",
      "Training batch 191\tloss: 2.4698\tacc: 0.2689\r",
      "Training batch 192\tloss: 2.4695\tacc: 0.2691\r",
      "Training batch 193\tloss: 2.4695\tacc: 0.2691\r",
      "Training batch 194\tloss: 2.4699\tacc: 0.2690\r",
      "Training batch 195\tloss: 2.4699\tacc: 0.2689\r",
      "Training batch 196\tloss: 2.4696\tacc: 0.2689\r",
      "Training batch 197\tloss: 2.4697\tacc: 0.2688\r",
      "Training batch 198\tloss: 2.4697\tacc: 0.2688\r",
      "Training batch 199\tloss: 2.4701\tacc: 0.2687\r",
      "Training batch 200\tloss: 2.4701\tacc: 0.2688\r",
      "Training batch 201\tloss: 2.4700\tacc: 0.2689\r",
      "Training batch 202\tloss: 2.4700\tacc: 0.2689\r",
      "Training batch 203\tloss: 2.4696\tacc: 0.2689\r",
      "Training batch 204\tloss: 2.4696\tacc: 0.2690\r",
      "Training batch 205\tloss: 2.4695\tacc: 0.2690\r",
      "Training batch 206\tloss: 2.4694\tacc: 0.2690\r",
      "Training batch 207\tloss: 2.4690\tacc: 0.2691\r",
      "Training batch 208\tloss: 2.4689\tacc: 0.2692\r",
      "Training batch 209\tloss: 2.4691\tacc: 0.2691\r",
      "Training batch 210\tloss: 2.4689\tacc: 0.2692\r",
      "Training batch 211\tloss: 2.4688\tacc: 0.2692\r",
      "Training batch 212\tloss: 2.4688\tacc: 0.2693\r",
      "Training batch 213\tloss: 2.4688\tacc: 0.2692\r",
      "Training batch 214\tloss: 2.4687\tacc: 0.2692\r",
      "Training batch 215\tloss: 2.4687\tacc: 0.2692\r",
      "Training batch 216\tloss: 2.4687\tacc: 0.2692\r",
      "Training batch 217\tloss: 2.4689\tacc: 0.2690\r",
      "Training batch 218\tloss: 2.4689\tacc: 0.2691\r",
      "Training batch 219\tloss: 2.4687\tacc: 0.2691\r",
      "Training batch 220\tloss: 2.4687\tacc: 0.2692\r",
      "Training batch 221\tloss: 2.4688\tacc: 0.2691\r",
      "Training batch 222\tloss: 2.4687\tacc: 0.2691\r",
      "Training batch 223\tloss: 2.4686\tacc: 0.2690\r",
      "Training batch 224\tloss: 2.4687\tacc: 0.2690\r",
      "Training batch 225\tloss: 2.4685\tacc: 0.2691\r",
      "Training batch 226\tloss: 2.4683\tacc: 0.2692\r",
      "Training batch 227\tloss: 2.4679\tacc: 0.2692\r",
      "Training batch 228\tloss: 2.4680\tacc: 0.2693\r",
      "Training batch 229\tloss: 2.4677\tacc: 0.2694\r",
      "Training batch 230\tloss: 2.4677\tacc: 0.2695\r",
      "Training batch 231\tloss: 2.4677\tacc: 0.2694\r",
      "Training batch 232\tloss: 2.4678\tacc: 0.2693\r",
      "Training batch 233\tloss: 2.4678\tacc: 0.2693\r",
      "Training batch 234\tloss: 2.4678\tacc: 0.2694\r",
      "Training batch 235\tloss: 2.4676\tacc: 0.2694\r",
      "Training batch 236\tloss: 2.4674\tacc: 0.2694\r",
      "Training batch 237\tloss: 2.4672\tacc: 0.2694\r",
      "Training batch 238\tloss: 2.4674\tacc: 0.2693\r",
      "Training batch 239\tloss: 2.4673\tacc: 0.2694\r",
      "Training batch 240\tloss: 2.4673\tacc: 0.2694\r",
      "Training batch 241\tloss: 2.4669\tacc: 0.2695\r",
      "Training batch 242\tloss: 2.4669\tacc: 0.2695\r",
      "Training batch 243\tloss: 2.4670\tacc: 0.2695\r",
      "Training batch 244\tloss: 2.4670\tacc: 0.2695\r",
      "Training batch 245\tloss: 2.4668\tacc: 0.2695\r",
      "Training batch 246\tloss: 2.4669\tacc: 0.2694\r",
      "Training batch 247\tloss: 2.4669\tacc: 0.2694\r",
      "Training batch 248\tloss: 2.4669\tacc: 0.2694\r",
      "Training batch 249\tloss: 2.4669\tacc: 0.2693\r",
      "Training batch 250\tloss: 2.4669\tacc: 0.2693\r",
      "Training batch 251\tloss: 2.4669\tacc: 0.2693\r",
      "Training batch 252\tloss: 2.4667\tacc: 0.2693\r",
      "Training batch 253\tloss: 2.4665\tacc: 0.2693\r",
      "Training batch 254\tloss: 2.4666\tacc: 0.2692\r",
      "Training batch 255\tloss: 2.4665\tacc: 0.2693\r",
      "Training batch 256\tloss: 2.4664\tacc: 0.2694\r",
      "Training batch 257\tloss: 2.4662\tacc: 0.2694\r",
      "Training batch 258\tloss: 2.4664\tacc: 0.2695\r",
      "Training batch 259\tloss: 2.4663\tacc: 0.2695\r",
      "Training batch 260\tloss: 2.4663\tacc: 0.2695\r",
      "Training batch 261\tloss: 2.4663\tacc: 0.2694\r",
      "Training batch 262\tloss: 2.4663\tacc: 0.2694\r",
      "Training batch 263\tloss: 2.4665\tacc: 0.2693\r",
      "Training batch 264\tloss: 2.4665\tacc: 0.2693\r",
      "Training batch 265\tloss: 2.4666\tacc: 0.2693\r",
      "Training batch 266\tloss: 2.4665\tacc: 0.2692\r",
      "Training batch 267\tloss: 2.4665\tacc: 0.2692\r",
      "Training batch 268\tloss: 2.4663\tacc: 0.2692\r",
      "Training batch 269\tloss: 2.4662\tacc: 0.2692\r",
      "Training batch 270\tloss: 2.4662\tacc: 0.2692\ttime: 70.170 s\n",
      "\r",
      "Validation batch 1\tloss: 2.3850\tacc: 0.3042\r",
      "Validation batch 2\tloss: 2.3885\tacc: 0.2916\r",
      "Validation batch 3\tloss: 2.3800\tacc: 0.2911\r",
      "Validation batch 4\tloss: 2.3888\tacc: 0.2879\r",
      "Validation batch 5\tloss: 2.3961\tacc: 0.2832\r",
      "Validation batch 6\tloss: 2.3917\tacc: 0.2811\r",
      "Validation batch 7\tloss: 2.4052\tacc: 0.2777\r",
      "Validation batch 8\tloss: 2.3975\tacc: 0.2802\r",
      "Validation batch 9\tloss: 2.3933\tacc: 0.2822\r",
      "Validation batch 10\tloss: 2.4025\tacc: 0.2798\r",
      "Validation batch 11\tloss: 2.4056\tacc: 0.2787\r",
      "Validation batch 12\tloss: 2.4047\tacc: 0.2789\r",
      "Validation batch 13\tloss: 2.4050\tacc: 0.2790\r",
      "Validation batch 14\tloss: 2.4054\tacc: 0.2786\r",
      "Validation batch 15\tloss: 2.4076\tacc: 0.2788\r",
      "Validation batch 16\tloss: 2.4061\tacc: 0.2789\r",
      "Validation batch 17\tloss: 2.4050\tacc: 0.2788\r",
      "Validation batch 18\tloss: 2.4057\tacc: 0.2789\r",
      "Validation batch 19\tloss: 2.4058\tacc: 0.2793\r",
      "Validation batch 20\tloss: 2.4053\tacc: 0.2789\r",
      "Validation batch 21\tloss: 2.4041\tacc: 0.2797\r",
      "Validation batch 22\tloss: 2.4043\tacc: 0.2796\r",
      "Validation batch 23\tloss: 2.4069\tacc: 0.2793\r",
      "Validation batch 24\tloss: 2.4070\tacc: 0.2789\r",
      "Validation batch 25\tloss: 2.4067\tacc: 0.2790\r",
      "Validation batch 26\tloss: 2.4060\tacc: 0.2797\r",
      "Validation batch 27\tloss: 2.4058\tacc: 0.2797\r",
      "Validation batch 28\tloss: 2.4063\tacc: 0.2797\r",
      "Validation batch 29\tloss: 2.4064\tacc: 0.2797\r",
      "Validation batch 30\tloss: 2.4082\tacc: 0.2789\r",
      "Validation batch 31\tloss: 2.4071\tacc: 0.2785\r",
      "Validation batch 32\tloss: 2.4079\tacc: 0.2783\r",
      "Validation batch 33\tloss: 2.4079\tacc: 0.2784\r",
      "Validation batch 34\tloss: 2.4084\tacc: 0.2782\r",
      "Validation batch 35\tloss: 2.4090\tacc: 0.2781\r",
      "Validation batch 36\tloss: 2.4104\tacc: 0.2778\r",
      "Validation batch 37\tloss: 2.4095\tacc: 0.2784\r",
      "Validation batch 38\tloss: 2.4095\tacc: 0.2786\r",
      "Validation batch 39\tloss: 2.4105\tacc: 0.2785\r",
      "Validation batch 40\tloss: 2.4113\tacc: 0.2785\r",
      "Validation batch 41\tloss: 2.4116\tacc: 0.2786\r",
      "Validation batch 42\tloss: 2.4121\tacc: 0.2784\r",
      "Validation batch 43\tloss: 2.4133\tacc: 0.2782\r",
      "Validation batch 44\tloss: 2.4139\tacc: 0.2782\r",
      "Validation batch 45\tloss: 2.4141\tacc: 0.2780\r",
      "Validation batch 46\tloss: 2.4131\tacc: 0.2780\r",
      "Validation batch 47\tloss: 2.4131\tacc: 0.2781\r",
      "Validation batch 48\tloss: 2.4124\tacc: 0.2785\r",
      "Validation batch 49\tloss: 2.4118\tacc: 0.2788\r",
      "Validation batch 50\tloss: 2.4121\tacc: 0.2786\r",
      "Validation batch 51\tloss: 2.4115\tacc: 0.2786\r",
      "Validation batch 52\tloss: 2.4114\tacc: 0.2787\r",
      "Validation batch 53\tloss: 2.4122\tacc: 0.2783\r",
      "Validation batch 54\tloss: 2.4134\tacc: 0.2781\r",
      "Validation batch 55\tloss: 2.4134\tacc: 0.2782\r",
      "Validation batch 56\tloss: 2.4125\tacc: 0.2785\r",
      "Validation batch 57\tloss: 2.4125\tacc: 0.2784\r",
      "Validation batch 58\tloss: 2.4125\tacc: 0.2785\r",
      "Validation batch 59\tloss: 2.4120\tacc: 0.2790\r",
      "Validation batch 60\tloss: 2.4117\tacc: 0.2792\r",
      "Validation batch 61\tloss: 2.4114\tacc: 0.2791\r",
      "Validation batch 62\tloss: 2.4116\tacc: 0.2789\r",
      "Validation batch 63\tloss: 2.4113\tacc: 0.2789\r",
      "Validation batch 64\tloss: 2.4118\tacc: 0.2787\r",
      "Validation batch 65\tloss: 2.4120\tacc: 0.2787\r",
      "Validation batch 66\tloss: 2.4124\tacc: 0.2787\r",
      "Validation batch 67\tloss: 2.4121\tacc: 0.2790\r",
      "Validation batch 68\tloss: 2.4121\tacc: 0.2790\r",
      "Validation batch 69\tloss: 2.4122\tacc: 0.2789\r",
      "Validation batch 70\tloss: 2.4130\tacc: 0.2788\r",
      "Validation batch 71\tloss: 2.4134\tacc: 0.2787\r",
      "Validation batch 72\tloss: 2.4140\tacc: 0.2786\r",
      "Validation batch 73\tloss: 2.4139\tacc: 0.2786\r",
      "Validation batch 74\tloss: 2.4138\tacc: 0.2786\r",
      "Validation batch 75\tloss: 2.4135\tacc: 0.2787\r",
      "Validation batch 76\tloss: 2.4134\tacc: 0.2788\r",
      "Validation batch 77\tloss: 2.4137\tacc: 0.2788\r",
      "Validation batch 78\tloss: 2.4140\tacc: 0.2789\r",
      "Validation batch 79\tloss: 2.4134\tacc: 0.2790\r",
      "Validation batch 80\tloss: 2.4135\tacc: 0.2788\r",
      "Validation batch 81\tloss: 2.4129\tacc: 0.2790\r",
      "Validation batch 82\tloss: 2.4135\tacc: 0.2789\r",
      "Validation batch 83\tloss: 2.4138\tacc: 0.2789\r",
      "Validation batch 84\tloss: 2.4136\tacc: 0.2790\r",
      "Validation batch 85\tloss: 2.4134\tacc: 0.2789\r",
      "Validation batch 86\tloss: 2.4138\tacc: 0.2788\r",
      "Validation batch 87\tloss: 2.4133\tacc: 0.2789\r",
      "Validation batch 88\tloss: 2.4132\tacc: 0.2789\r",
      "Validation batch 89\tloss: 2.4133\tacc: 0.2790\r",
      "Validation batch 90\tloss: 2.4136\tacc: 0.2789\ttime: 7.704 s\n",
      "The chkpt file has been updated at epoch 4.\n",
      "Epoch 5 of 5 \n",
      "\r",
      "Training batch 1\tloss: 2.4402\tacc: 0.2796\r",
      "Training batch 2\tloss: 2.4557\tacc: 0.2772\r",
      "Training batch 3\tloss: 2.4557\tacc: 0.2786\r",
      "Training batch 4\tloss: 2.4361\tacc: 0.2815\r",
      "Training batch 5\tloss: 2.4245\tacc: 0.2826\r",
      "Training batch 6\tloss: 2.4270\tacc: 0.2811\r",
      "Training batch 7\tloss: 2.4298\tacc: 0.2810\r",
      "Training batch 8\tloss: 2.4262\tacc: 0.2806\r",
      "Training batch 9\tloss: 2.4311\tacc: 0.2778\r",
      "Training batch 10\tloss: 2.4279\tacc: 0.2803\r",
      "Training batch 11\tloss: 2.4293\tacc: 0.2805\r",
      "Training batch 12\tloss: 2.4304\tacc: 0.2797\r",
      "Training batch 13\tloss: 2.4322\tacc: 0.2783\r",
      "Training batch 14\tloss: 2.4350\tacc: 0.2777\r",
      "Training batch 15\tloss: 2.4407\tacc: 0.2759\r",
      "Training batch 16\tloss: 2.4416\tacc: 0.2748\r",
      "Training batch 17\tloss: 2.4372\tacc: 0.2761\r",
      "Training batch 18\tloss: 2.4388\tacc: 0.2756\r",
      "Training batch 19\tloss: 2.4405\tacc: 0.2754\r",
      "Training batch 20\tloss: 2.4381\tacc: 0.2759\r",
      "Training batch 21\tloss: 2.4398\tacc: 0.2755\r",
      "Training batch 22\tloss: 2.4387\tacc: 0.2750\r",
      "Training batch 23\tloss: 2.4394\tacc: 0.2743\r",
      "Training batch 24\tloss: 2.4419\tacc: 0.2737\r",
      "Training batch 25\tloss: 2.4405\tacc: 0.2742\r",
      "Training batch 26\tloss: 2.4395\tacc: 0.2747\r",
      "Training batch 27\tloss: 2.4405\tacc: 0.2743\r",
      "Training batch 28\tloss: 2.4397\tacc: 0.2741\r",
      "Training batch 29\tloss: 2.4389\tacc: 0.2738\r",
      "Training batch 30\tloss: 2.4390\tacc: 0.2744\r",
      "Training batch 31\tloss: 2.4406\tacc: 0.2742\r",
      "Training batch 32\tloss: 2.4397\tacc: 0.2747\r",
      "Training batch 33\tloss: 2.4401\tacc: 0.2745\r",
      "Training batch 34\tloss: 2.4400\tacc: 0.2743\r",
      "Training batch 35\tloss: 2.4394\tacc: 0.2743\r",
      "Training batch 36\tloss: 2.4414\tacc: 0.2737\r",
      "Training batch 37\tloss: 2.4422\tacc: 0.2734\r",
      "Training batch 38\tloss: 2.4432\tacc: 0.2730\r",
      "Training batch 39\tloss: 2.4435\tacc: 0.2732\r",
      "Training batch 40\tloss: 2.4437\tacc: 0.2729\r",
      "Training batch 41\tloss: 2.4430\tacc: 0.2725\r",
      "Training batch 42\tloss: 2.4434\tacc: 0.2724\r",
      "Training batch 43\tloss: 2.4434\tacc: 0.2724\r",
      "Training batch 44\tloss: 2.4438\tacc: 0.2722\r",
      "Training batch 45\tloss: 2.4428\tacc: 0.2723\r",
      "Training batch 46\tloss: 2.4434\tacc: 0.2721\r",
      "Training batch 47\tloss: 2.4425\tacc: 0.2722\r",
      "Training batch 48\tloss: 2.4421\tacc: 0.2723\r",
      "Training batch 49\tloss: 2.4404\tacc: 0.2728\r",
      "Training batch 50\tloss: 2.4397\tacc: 0.2731\r",
      "Training batch 51\tloss: 2.4389\tacc: 0.2734\r",
      "Training batch 52\tloss: 2.4385\tacc: 0.2735\r",
      "Training batch 53\tloss: 2.4386\tacc: 0.2737\r",
      "Training batch 54\tloss: 2.4390\tacc: 0.2737\r",
      "Training batch 55\tloss: 2.4399\tacc: 0.2738\r",
      "Training batch 56\tloss: 2.4393\tacc: 0.2736\r",
      "Training batch 57\tloss: 2.4388\tacc: 0.2738\r",
      "Training batch 58\tloss: 2.4394\tacc: 0.2736\r",
      "Training batch 59\tloss: 2.4391\tacc: 0.2736\r",
      "Training batch 60\tloss: 2.4401\tacc: 0.2734\r",
      "Training batch 61\tloss: 2.4401\tacc: 0.2736\r",
      "Training batch 62\tloss: 2.4399\tacc: 0.2737\r",
      "Training batch 63\tloss: 2.4400\tacc: 0.2738\r",
      "Training batch 64\tloss: 2.4399\tacc: 0.2737\r",
      "Training batch 65\tloss: 2.4402\tacc: 0.2737\r",
      "Training batch 66\tloss: 2.4411\tacc: 0.2732\r",
      "Training batch 67\tloss: 2.4407\tacc: 0.2732\r",
      "Training batch 68\tloss: 2.4409\tacc: 0.2732\r",
      "Training batch 69\tloss: 2.4418\tacc: 0.2729\r",
      "Training batch 70\tloss: 2.4425\tacc: 0.2728\r",
      "Training batch 71\tloss: 2.4431\tacc: 0.2727\r",
      "Training batch 72\tloss: 2.4424\tacc: 0.2730\r",
      "Training batch 73\tloss: 2.4422\tacc: 0.2731\r",
      "Training batch 74\tloss: 2.4421\tacc: 0.2730\r",
      "Training batch 75\tloss: 2.4412\tacc: 0.2733\r",
      "Training batch 76\tloss: 2.4411\tacc: 0.2734\r",
      "Training batch 77\tloss: 2.4411\tacc: 0.2733\r",
      "Training batch 78\tloss: 2.4410\tacc: 0.2733\r",
      "Training batch 79\tloss: 2.4415\tacc: 0.2733\r",
      "Training batch 80\tloss: 2.4427\tacc: 0.2732\r",
      "Training batch 81\tloss: 2.4437\tacc: 0.2729\r",
      "Training batch 82\tloss: 2.4431\tacc: 0.2731\r",
      "Training batch 83\tloss: 2.4432\tacc: 0.2731\r",
      "Training batch 84\tloss: 2.4435\tacc: 0.2729\r",
      "Training batch 85\tloss: 2.4434\tacc: 0.2728\r",
      "Training batch 86\tloss: 2.4437\tacc: 0.2728\r",
      "Training batch 87\tloss: 2.4434\tacc: 0.2729\r",
      "Training batch 88\tloss: 2.4435\tacc: 0.2729\r",
      "Training batch 89\tloss: 2.4437\tacc: 0.2729\r",
      "Training batch 90\tloss: 2.4441\tacc: 0.2728\r",
      "Training batch 91\tloss: 2.4447\tacc: 0.2728\r",
      "Training batch 92\tloss: 2.4452\tacc: 0.2725\r",
      "Training batch 93\tloss: 2.4442\tacc: 0.2728\r",
      "Training batch 94\tloss: 2.4446\tacc: 0.2726\r",
      "Training batch 95\tloss: 2.4447\tacc: 0.2724\r",
      "Training batch 96\tloss: 2.4447\tacc: 0.2722\r",
      "Training batch 97\tloss: 2.4452\tacc: 0.2721\r",
      "Training batch 98\tloss: 2.4448\tacc: 0.2722\r",
      "Training batch 99\tloss: 2.4452\tacc: 0.2721\r",
      "Training batch 100\tloss: 2.4454\tacc: 0.2721\r",
      "Training batch 101\tloss: 2.4456\tacc: 0.2720\r",
      "Training batch 102\tloss: 2.4456\tacc: 0.2721\r",
      "Training batch 103\tloss: 2.4456\tacc: 0.2720\r",
      "Training batch 104\tloss: 2.4459\tacc: 0.2719\r",
      "Training batch 105\tloss: 2.4458\tacc: 0.2721\r",
      "Training batch 106\tloss: 2.4465\tacc: 0.2720\r",
      "Training batch 107\tloss: 2.4460\tacc: 0.2720\r",
      "Training batch 108\tloss: 2.4457\tacc: 0.2721\r",
      "Training batch 109\tloss: 2.4454\tacc: 0.2720\r",
      "Training batch 110\tloss: 2.4458\tacc: 0.2719\r",
      "Training batch 111\tloss: 2.4454\tacc: 0.2720\r",
      "Training batch 112\tloss: 2.4453\tacc: 0.2721\r",
      "Training batch 113\tloss: 2.4450\tacc: 0.2723\r",
      "Training batch 114\tloss: 2.4450\tacc: 0.2724\r",
      "Training batch 115\tloss: 2.4451\tacc: 0.2723\r",
      "Training batch 116\tloss: 2.4451\tacc: 0.2724\r",
      "Training batch 117\tloss: 2.4450\tacc: 0.2726\r",
      "Training batch 118\tloss: 2.4450\tacc: 0.2727\r",
      "Training batch 119\tloss: 2.4452\tacc: 0.2726\r",
      "Training batch 120\tloss: 2.4455\tacc: 0.2726\r",
      "Training batch 121\tloss: 2.4455\tacc: 0.2726\r",
      "Training batch 122\tloss: 2.4450\tacc: 0.2726\r",
      "Training batch 123\tloss: 2.4449\tacc: 0.2726\r",
      "Training batch 124\tloss: 2.4447\tacc: 0.2727\r",
      "Training batch 125\tloss: 2.4443\tacc: 0.2728\r",
      "Training batch 126\tloss: 2.4438\tacc: 0.2730\r",
      "Training batch 127\tloss: 2.4435\tacc: 0.2731\r",
      "Training batch 128\tloss: 2.4433\tacc: 0.2732\r",
      "Training batch 129\tloss: 2.4432\tacc: 0.2732\r",
      "Training batch 130\tloss: 2.4430\tacc: 0.2732\r",
      "Training batch 131\tloss: 2.4430\tacc: 0.2733\r",
      "Training batch 132\tloss: 2.4426\tacc: 0.2733\r",
      "Training batch 133\tloss: 2.4423\tacc: 0.2734\r",
      "Training batch 134\tloss: 2.4421\tacc: 0.2735\r",
      "Training batch 135\tloss: 2.4419\tacc: 0.2735\r",
      "Training batch 136\tloss: 2.4418\tacc: 0.2735\r",
      "Training batch 137\tloss: 2.4416\tacc: 0.2736\r",
      "Training batch 138\tloss: 2.4420\tacc: 0.2735\r",
      "Training batch 139\tloss: 2.4420\tacc: 0.2735\r",
      "Training batch 140\tloss: 2.4421\tacc: 0.2735\r",
      "Training batch 141\tloss: 2.4417\tacc: 0.2736\r",
      "Training batch 142\tloss: 2.4419\tacc: 0.2736\r",
      "Training batch 143\tloss: 2.4416\tacc: 0.2736\r",
      "Training batch 144\tloss: 2.4412\tacc: 0.2736\r",
      "Training batch 145\tloss: 2.4411\tacc: 0.2737\r",
      "Training batch 146\tloss: 2.4409\tacc: 0.2737\r",
      "Training batch 147\tloss: 2.4411\tacc: 0.2737\r",
      "Training batch 148\tloss: 2.4410\tacc: 0.2737\r",
      "Training batch 149\tloss: 2.4404\tacc: 0.2739\r",
      "Training batch 150\tloss: 2.4404\tacc: 0.2738\r",
      "Training batch 151\tloss: 2.4401\tacc: 0.2739\r",
      "Training batch 152\tloss: 2.4403\tacc: 0.2739\r",
      "Training batch 153\tloss: 2.4402\tacc: 0.2739\r",
      "Training batch 154\tloss: 2.4401\tacc: 0.2740\r",
      "Training batch 155\tloss: 2.4406\tacc: 0.2739\r",
      "Training batch 156\tloss: 2.4401\tacc: 0.2739\r",
      "Training batch 157\tloss: 2.4400\tacc: 0.2739\r",
      "Training batch 158\tloss: 2.4401\tacc: 0.2739\r",
      "Training batch 159\tloss: 2.4403\tacc: 0.2739\r",
      "Training batch 160\tloss: 2.4400\tacc: 0.2739\r",
      "Training batch 161\tloss: 2.4397\tacc: 0.2739\r",
      "Training batch 162\tloss: 2.4397\tacc: 0.2740\r",
      "Training batch 163\tloss: 2.4394\tacc: 0.2739\r",
      "Training batch 164\tloss: 2.4397\tacc: 0.2738\r",
      "Training batch 165\tloss: 2.4398\tacc: 0.2737\r",
      "Training batch 166\tloss: 2.4397\tacc: 0.2739\r",
      "Training batch 167\tloss: 2.4393\tacc: 0.2740\r",
      "Training batch 168\tloss: 2.4391\tacc: 0.2740\r",
      "Training batch 169\tloss: 2.4393\tacc: 0.2740\r",
      "Training batch 170\tloss: 2.4392\tacc: 0.2740\r",
      "Training batch 171\tloss: 2.4390\tacc: 0.2740\r",
      "Training batch 172\tloss: 2.4390\tacc: 0.2740\r",
      "Training batch 173\tloss: 2.4387\tacc: 0.2742\r",
      "Training batch 174\tloss: 2.4388\tacc: 0.2742\r",
      "Training batch 175\tloss: 2.4386\tacc: 0.2743\r",
      "Training batch 176\tloss: 2.4385\tacc: 0.2743\r",
      "Training batch 177\tloss: 2.4383\tacc: 0.2744\r",
      "Training batch 178\tloss: 2.4382\tacc: 0.2744\r",
      "Training batch 179\tloss: 2.4384\tacc: 0.2743\r",
      "Training batch 180\tloss: 2.4387\tacc: 0.2743\r",
      "Training batch 181\tloss: 2.4384\tacc: 0.2744\r",
      "Training batch 182\tloss: 2.4385\tacc: 0.2743\r",
      "Training batch 183\tloss: 2.4384\tacc: 0.2743\r",
      "Training batch 184\tloss: 2.4383\tacc: 0.2744\r",
      "Training batch 185\tloss: 2.4385\tacc: 0.2743\r",
      "Training batch 186\tloss: 2.4386\tacc: 0.2742\r",
      "Training batch 187\tloss: 2.4387\tacc: 0.2742\r",
      "Training batch 188\tloss: 2.4387\tacc: 0.2743\r",
      "Training batch 189\tloss: 2.4386\tacc: 0.2744\r",
      "Training batch 190\tloss: 2.4385\tacc: 0.2744\r",
      "Training batch 191\tloss: 2.4384\tacc: 0.2745\r",
      "Training batch 192\tloss: 2.4385\tacc: 0.2745\r",
      "Training batch 193\tloss: 2.4384\tacc: 0.2745\r",
      "Training batch 194\tloss: 2.4385\tacc: 0.2745\r",
      "Training batch 195\tloss: 2.4385\tacc: 0.2745\r",
      "Training batch 196\tloss: 2.4387\tacc: 0.2744\r",
      "Training batch 197\tloss: 2.4386\tacc: 0.2744\r",
      "Training batch 198\tloss: 2.4387\tacc: 0.2744\r",
      "Training batch 199\tloss: 2.4387\tacc: 0.2744\r",
      "Training batch 200\tloss: 2.4385\tacc: 0.2744\r",
      "Training batch 201\tloss: 2.4383\tacc: 0.2744\r",
      "Training batch 202\tloss: 2.4381\tacc: 0.2745\r",
      "Training batch 203\tloss: 2.4379\tacc: 0.2745\r",
      "Training batch 204\tloss: 2.4377\tacc: 0.2746\r",
      "Training batch 205\tloss: 2.4379\tacc: 0.2746\r",
      "Training batch 206\tloss: 2.4379\tacc: 0.2745\r",
      "Training batch 207\tloss: 2.4376\tacc: 0.2746\r",
      "Training batch 208\tloss: 2.4374\tacc: 0.2747\r",
      "Training batch 209\tloss: 2.4373\tacc: 0.2747\r",
      "Training batch 210\tloss: 2.4374\tacc: 0.2747\r",
      "Training batch 211\tloss: 2.4371\tacc: 0.2748\r",
      "Training batch 212\tloss: 2.4370\tacc: 0.2748\r",
      "Training batch 213\tloss: 2.4371\tacc: 0.2749\r",
      "Training batch 214\tloss: 2.4368\tacc: 0.2749\r",
      "Training batch 215\tloss: 2.4366\tacc: 0.2750\r",
      "Training batch 216\tloss: 2.4367\tacc: 0.2750\r",
      "Training batch 217\tloss: 2.4369\tacc: 0.2749\r",
      "Training batch 218\tloss: 2.4374\tacc: 0.2748\r",
      "Training batch 219\tloss: 2.4372\tacc: 0.2748\r",
      "Training batch 220\tloss: 2.4372\tacc: 0.2748\r",
      "Training batch 221\tloss: 2.4370\tacc: 0.2748\r",
      "Training batch 222\tloss: 2.4369\tacc: 0.2747\r",
      "Training batch 223\tloss: 2.4367\tacc: 0.2747\r",
      "Training batch 224\tloss: 2.4367\tacc: 0.2747\r",
      "Training batch 225\tloss: 2.4370\tacc: 0.2747\r",
      "Training batch 226\tloss: 2.4369\tacc: 0.2747\r",
      "Training batch 227\tloss: 2.4368\tacc: 0.2747\r",
      "Training batch 228\tloss: 2.4370\tacc: 0.2747\r",
      "Training batch 229\tloss: 2.4372\tacc: 0.2747\r",
      "Training batch 230\tloss: 2.4373\tacc: 0.2747\r",
      "Training batch 231\tloss: 2.4372\tacc: 0.2748\r",
      "Training batch 232\tloss: 2.4372\tacc: 0.2747\r",
      "Training batch 233\tloss: 2.4373\tacc: 0.2747\r",
      "Training batch 234\tloss: 2.4373\tacc: 0.2746\r",
      "Training batch 235\tloss: 2.4375\tacc: 0.2746\r",
      "Training batch 236\tloss: 2.4375\tacc: 0.2746\r",
      "Training batch 237\tloss: 2.4375\tacc: 0.2746\r",
      "Training batch 238\tloss: 2.4373\tacc: 0.2746\r",
      "Training batch 239\tloss: 2.4373\tacc: 0.2745\r",
      "Training batch 240\tloss: 2.4372\tacc: 0.2745\r",
      "Training batch 241\tloss: 2.4371\tacc: 0.2745\r",
      "Training batch 242\tloss: 2.4372\tacc: 0.2745\r",
      "Training batch 243\tloss: 2.4372\tacc: 0.2745\r",
      "Training batch 244\tloss: 2.4371\tacc: 0.2745\r",
      "Training batch 245\tloss: 2.4370\tacc: 0.2745\r",
      "Training batch 246\tloss: 2.4368\tacc: 0.2746\r",
      "Training batch 247\tloss: 2.4370\tacc: 0.2746\r",
      "Training batch 248\tloss: 2.4370\tacc: 0.2746\r",
      "Training batch 249\tloss: 2.4370\tacc: 0.2746\r",
      "Training batch 250\tloss: 2.4368\tacc: 0.2747\r",
      "Training batch 251\tloss: 2.4369\tacc: 0.2746\r",
      "Training batch 252\tloss: 2.4369\tacc: 0.2747\r",
      "Training batch 253\tloss: 2.4366\tacc: 0.2748\r",
      "Training batch 254\tloss: 2.4366\tacc: 0.2748\r",
      "Training batch 255\tloss: 2.4365\tacc: 0.2748\r",
      "Training batch 256\tloss: 2.4364\tacc: 0.2748\r",
      "Training batch 257\tloss: 2.4365\tacc: 0.2748\r",
      "Training batch 258\tloss: 2.4366\tacc: 0.2748\r",
      "Training batch 259\tloss: 2.4364\tacc: 0.2748\r",
      "Training batch 260\tloss: 2.4366\tacc: 0.2748\r",
      "Training batch 261\tloss: 2.4364\tacc: 0.2748\r",
      "Training batch 262\tloss: 2.4366\tacc: 0.2748\r",
      "Training batch 263\tloss: 2.4365\tacc: 0.2748\r",
      "Training batch 264\tloss: 2.4364\tacc: 0.2748\r",
      "Training batch 265\tloss: 2.4364\tacc: 0.2748\r",
      "Training batch 266\tloss: 2.4365\tacc: 0.2747\r",
      "Training batch 267\tloss: 2.4365\tacc: 0.2746\r",
      "Training batch 268\tloss: 2.4363\tacc: 0.2746\r",
      "Training batch 269\tloss: 2.4362\tacc: 0.2746\r",
      "Training batch 270\tloss: 2.4361\tacc: 0.2746\ttime: 70.189 s\n",
      "\r",
      "Validation batch 1\tloss: 2.3569\tacc: 0.3106\r",
      "Validation batch 2\tloss: 2.3602\tacc: 0.2959\r",
      "Validation batch 3\tloss: 2.3526\tacc: 0.2955\r",
      "Validation batch 4\tloss: 2.3628\tacc: 0.2936\r",
      "Validation batch 5\tloss: 2.3711\tacc: 0.2904\r",
      "Validation batch 6\tloss: 2.3672\tacc: 0.2888\r",
      "Validation batch 7\tloss: 2.3820\tacc: 0.2845\r",
      "Validation batch 8\tloss: 2.3748\tacc: 0.2867\r",
      "Validation batch 9\tloss: 2.3704\tacc: 0.2885\r",
      "Validation batch 10\tloss: 2.3790\tacc: 0.2866\r",
      "Validation batch 11\tloss: 2.3821\tacc: 0.2857\r",
      "Validation batch 12\tloss: 2.3806\tacc: 0.2865\r",
      "Validation batch 13\tloss: 2.3803\tacc: 0.2860\r",
      "Validation batch 14\tloss: 2.3808\tacc: 0.2856\r",
      "Validation batch 15\tloss: 2.3834\tacc: 0.2854\r",
      "Validation batch 16\tloss: 2.3822\tacc: 0.2854\r",
      "Validation batch 17\tloss: 2.3811\tacc: 0.2855\r",
      "Validation batch 18\tloss: 2.3821\tacc: 0.2854\r",
      "Validation batch 19\tloss: 2.3825\tacc: 0.2855\r",
      "Validation batch 20\tloss: 2.3823\tacc: 0.2848\r",
      "Validation batch 21\tloss: 2.3812\tacc: 0.2859\r",
      "Validation batch 22\tloss: 2.3814\tacc: 0.2857\r",
      "Validation batch 23\tloss: 2.3843\tacc: 0.2854\r",
      "Validation batch 24\tloss: 2.3842\tacc: 0.2852\r",
      "Validation batch 25\tloss: 2.3840\tacc: 0.2850\r",
      "Validation batch 26\tloss: 2.3832\tacc: 0.2858\r",
      "Validation batch 27\tloss: 2.3832\tacc: 0.2857\r",
      "Validation batch 28\tloss: 2.3840\tacc: 0.2854\r",
      "Validation batch 29\tloss: 2.3839\tacc: 0.2857\r",
      "Validation batch 30\tloss: 2.3857\tacc: 0.2852\r",
      "Validation batch 31\tloss: 2.3846\tacc: 0.2850\r",
      "Validation batch 32\tloss: 2.3856\tacc: 0.2845\r",
      "Validation batch 33\tloss: 2.3856\tacc: 0.2844\r",
      "Validation batch 34\tloss: 2.3863\tacc: 0.2843\r",
      "Validation batch 35\tloss: 2.3869\tacc: 0.2840\r",
      "Validation batch 36\tloss: 2.3884\tacc: 0.2837\r",
      "Validation batch 37\tloss: 2.3876\tacc: 0.2841\r",
      "Validation batch 38\tloss: 2.3877\tacc: 0.2843\r",
      "Validation batch 39\tloss: 2.3887\tacc: 0.2840\r",
      "Validation batch 40\tloss: 2.3896\tacc: 0.2839\r",
      "Validation batch 41\tloss: 2.3900\tacc: 0.2838\r",
      "Validation batch 42\tloss: 2.3905\tacc: 0.2839\r",
      "Validation batch 43\tloss: 2.3916\tacc: 0.2836\r",
      "Validation batch 44\tloss: 2.3924\tacc: 0.2835\r",
      "Validation batch 45\tloss: 2.3926\tacc: 0.2834\r",
      "Validation batch 46\tloss: 2.3915\tacc: 0.2833\r",
      "Validation batch 47\tloss: 2.3915\tacc: 0.2834\r",
      "Validation batch 48\tloss: 2.3908\tacc: 0.2837\r",
      "Validation batch 49\tloss: 2.3901\tacc: 0.2841\r",
      "Validation batch 50\tloss: 2.3905\tacc: 0.2839\r",
      "Validation batch 51\tloss: 2.3899\tacc: 0.2840\r",
      "Validation batch 52\tloss: 2.3898\tacc: 0.2841\r",
      "Validation batch 53\tloss: 2.3905\tacc: 0.2838\r",
      "Validation batch 54\tloss: 2.3918\tacc: 0.2835\r",
      "Validation batch 55\tloss: 2.3918\tacc: 0.2836\r",
      "Validation batch 56\tloss: 2.3908\tacc: 0.2839\r",
      "Validation batch 57\tloss: 2.3909\tacc: 0.2838\r",
      "Validation batch 58\tloss: 2.3909\tacc: 0.2838\r",
      "Validation batch 59\tloss: 2.3904\tacc: 0.2843\r",
      "Validation batch 60\tloss: 2.3900\tacc: 0.2845\r",
      "Validation batch 61\tloss: 2.3898\tacc: 0.2844\r",
      "Validation batch 62\tloss: 2.3900\tacc: 0.2843\r",
      "Validation batch 63\tloss: 2.3897\tacc: 0.2843\r",
      "Validation batch 64\tloss: 2.3902\tacc: 0.2841\r",
      "Validation batch 65\tloss: 2.3904\tacc: 0.2842\r",
      "Validation batch 66\tloss: 2.3908\tacc: 0.2842\r",
      "Validation batch 67\tloss: 2.3905\tacc: 0.2845\r",
      "Validation batch 68\tloss: 2.3905\tacc: 0.2846\r",
      "Validation batch 69\tloss: 2.3906\tacc: 0.2844\r",
      "Validation batch 70\tloss: 2.3914\tacc: 0.2842\r",
      "Validation batch 71\tloss: 2.3918\tacc: 0.2841\r",
      "Validation batch 72\tloss: 2.3924\tacc: 0.2840\r",
      "Validation batch 73\tloss: 2.3923\tacc: 0.2840\r",
      "Validation batch 74\tloss: 2.3921\tacc: 0.2841\r",
      "Validation batch 75\tloss: 2.3918\tacc: 0.2842\r",
      "Validation batch 76\tloss: 2.3918\tacc: 0.2842\r",
      "Validation batch 77\tloss: 2.3921\tacc: 0.2840\r",
      "Validation batch 78\tloss: 2.3924\tacc: 0.2840\r",
      "Validation batch 79\tloss: 2.3918\tacc: 0.2841\r",
      "Validation batch 80\tloss: 2.3919\tacc: 0.2840\r",
      "Validation batch 81\tloss: 2.3914\tacc: 0.2841\r",
      "Validation batch 82\tloss: 2.3920\tacc: 0.2839\r",
      "Validation batch 83\tloss: 2.3924\tacc: 0.2839\r",
      "Validation batch 84\tloss: 2.3921\tacc: 0.2840\r",
      "Validation batch 85\tloss: 2.3920\tacc: 0.2840\r",
      "Validation batch 86\tloss: 2.3924\tacc: 0.2839\r",
      "Validation batch 87\tloss: 2.3919\tacc: 0.2840\r",
      "Validation batch 88\tloss: 2.3919\tacc: 0.2840\r",
      "Validation batch 89\tloss: 2.3919\tacc: 0.2840\r",
      "Validation batch 90\tloss: 2.3923\tacc: 0.2839\ttime: 7.716 s\n",
      "The chkpt file has been updated at epoch 5.\n"
     ]
    }
   ],
   "source": [
    "train_file = h5py.File('../data/train_tokens.hdf5') # NOTE THIS IS DONE WITH TRAIN_TOKENS, not augmented\n",
    "val_file = h5py.File('../data/validate_tokens.hdf5')\n",
    "history = clf.train(train_file, val_file, epochs=epochs, batch_size=batch_size,\n",
    "                           save_model='../outputs/models/' + chkpt_name, save_mode='best')\n",
    "train_file.close()\n",
    "val_file.close() #save model and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_acc': [0.032838449031177004,\n",
       "  0.221060155305155,\n",
       "  0.25779425025383235,\n",
       "  0.26923741429460646,\n",
       "  0.2746406704487093],\n",
       " 'train_loss': [16.69040113644701,\n",
       "  2.871120259628433,\n",
       "  2.5251288869832975,\n",
       "  2.4661662981378196,\n",
       "  2.4361349791951046],\n",
       " 'val_acc': [0.19888388736634338,\n",
       "  0.2673487354983457,\n",
       "  0.2781406642716158,\n",
       "  0.27886485949192735,\n",
       "  0.283884526362126],\n",
       " 'val_loss': [3.7115966238724387,\n",
       "  2.52378467314811,\n",
       "  2.445869003895434,\n",
       "  2.413643034213787,\n",
       "  2.3923217015947382]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_size\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = self.forward(*input, **kwargs)\n",
      "/home/ubuntu/signal_peptide/code/translator.py:350: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.model.prob_projection(dec_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MAVRPTRRCLLALLLCFAWWAMA.                                               \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRQLNYYIFISTILTYNLTHG.                                                 \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNRIWLRAIILTASSALLAG.                                                  \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRINHKPLLIATALLTLVPNVVWS.                                              \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MGMFVLLLYTFLYAGDLGHG.                                                  \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLTCMMIVAVMFLTASIFITA.                                                \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNFKLIFLVALVLMAAFLGQTEG.                                               \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRLSTSALVLGAASSAV.                                                     \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNLASVLLLLAACHLSVSVNG.                                                 \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MLGIWTLLPLVLTYVVRLLSKCVNA.                                             \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MYAASILILHLTWAVATIA.                                                   \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MACRSWVLGILLVLVG.                                                      \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLLGFLIVGLSAISA.                                                      \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MAMIPSISKLLFVAICLF.                                                    \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MAVRPGLWPALLGIVLTAWLRGSGA.                                             \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MELDRAVGVLGAATLLLSFLGMAWA.                                             \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MENRKTFSWLKEQMIRSISVSIMIYVITRTSISNA.                                   \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MPGLGRRAQWLCWWWGLLCS.                                                  \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MVWKVAVFLSVALGIGA.                                                     \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MSGLSRPLLLAVGCLAALCVITAA.                                              \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MQIRYFLALSLLPQVVLA.                                                    \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRSAMLFAAVLALSLAWTFG.                                                  \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRRALLLAALLACAPPAFA.                                                   \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MSLSRRQFIQASGLAMCLGALPFAVQA.                                           \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MALWLQAFTLLVLLVLSSPGAQS.                                               \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MELPILKTNAITAILAAVTLCFASS.                                             \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MTAGLCVCVLLAVLCTSCLG.                                                  \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRLLSFIYLVWLALLTGTPQVSA.                                               \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKYFSVLVVLTLILAIVDQSDA.                                                \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKFLVLALCIAAAVA.                                                       \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MGSSGLLSLLVLFVLLANVQG.                                                 \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNLIIYVTIIALTSA.                                                       \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRGKHIFIITALISILMLAA.                                                  \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MPGQISAVAVLFLSLTVILHG.                                                 \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLLILCLLYYTQLVIC.                                                     \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKSLTLLTICAVLSVSLS.                                                    \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLNPSLLTAAGLVSAQLASA.                                                 \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MSTQPTKTSSTKLRIFKWLFIISTLVAIA.                                         \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MYGIEYTTVLTFLISFILLNYILKSLTRMMDFVIYRFLFVIVVLSPLLKA.                    \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MDVALKLLLLAALTLLASA.                                                   \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRLAPLYRNALLLTGLLLSGIAAVQA.                                            \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKQQKRLYARLLTLLFALIFLLPHSAAAA.                                         \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLLKTVPAIVMLAGGMFASLNA.                                               \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLTCVMIVAVLFLTAWTVVTA.                                                \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MFFWLMCYLVDVWLISA.                                                     \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MMSKLGVLLTICLLLFPLTVLP.                                                \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MAAAIPRAASLSPLFPLLFLLSAPQDSSG.                                         \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MWPAPCSVGRLLIFFMCSSSGYVVQG.                                            \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKTLLLLAFFVGVTCG.                                                      \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNTVRVTFLLVFVLAVSLGRA.                                                 \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLSKLLQLAVFSSLVTS.                                                    \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MTRMTRHLALWMLLSLAILASQSAMA.                                            \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MPLLFLWFFLTSTSLVSA.                                                    \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MVRSMRSRVAARAVAWALAVMPLAGAAGLTMAASPAAVA.                               \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKPKSKVAESTAASCFLVMSLLCSCIIG.                                          \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRLVVCLVFLASFALVCQG.                                                   \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MELGGPGAPPPPLLPPLLLLLGAGFLPASSP.                                       \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MGTPRGLRNAGSSSSACRFLAAFAVLLALPTLTAG.                                   \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKVLWAALLVAFLAGCQG.                                                    \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MCLPSCLLSIWVLFMAAQSLG.                                                 \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MTVLNRLHVCSLLAVSSLGMLPVGVFA.                                           \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKKWLVTIAALWLAG.                                                       \n",
      "\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MSGTILENLSGRKLSILVASLLLCQVFCFLLGGLY.                                   \n",
      "\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKFFTVLLFVSLAATSLAL.                                                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See how well it does on first batch_size test sequences\n",
    "file = h5py.File('../data/test_tokens.hdf5')\n",
    "training_data = SignalTranslator.generator_from_h5(file, batch_size, shuffle=False, use_cuda=True)\n",
    "src, tgt = next(training_data) # src is prot sequence, tgt is signal pep\n",
    "file.close()\n",
    "decoded, all_hyp, all_scores, enc_outputs, dec_outputs, enc_slf_attns, dec_slf_attns, dec_enc_attn = clf.translate_batch(src, 1) # predict signal pep from src (prot seq)\n",
    "for tg, dec in zip(tgt[0], decoded):\n",
    "    print(dec) # model's predictions\n",
    "    print(ctable.decode(tg.data.cpu().numpy())[:]) # tgt (actual signal peptide of src)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x378 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5.25))\n",
    "x = np.arange(len(history['train_loss']))\n",
    "_ = axs[0].plot(x, history['train_loss'], label='training loss', alpha=0.8)\n",
    "_ = axs[0].plot(x, history['val_loss'], label='validation loss', alpha=0.8)\n",
    "_ = axs[0].legend()\n",
    "_ = axs[1].plot(x, history['train_acc'], label='training accuracy', alpha=0.8)\n",
    "_ = axs[1].plot(x, history['val_acc'], label='validation accuracy', alpha=0.8)\n",
    "_ = axs[1].legend() #validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(data, x, y, ax):\n",
    "    sns.heatmap(data, \n",
    "                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n",
    "                    cbar=False, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh code in jupyter notebook, when code in *.py files has been updated\n",
    "import importlib\n",
    "import translator\n",
    "_ = importlib.reload(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_size\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = self.forward(*input, **kwargs)\n",
      "/home/ubuntu/signal_peptide/code/translator.py:350: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.model.prob_projection(dec_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MAVRPTRRCLLALLLCFAWWAMA.                                               \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRQLNYYIFISTILTYNLTHG.                                                 \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNRIWLRAIILTASSALLAG.                                                  \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRINHKPLLIATALLTLVPNVVWS.                                              \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MGMFVLLLYTFLYAGDLGHG.                                                  \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLTCMMIVAVMFLTASIFITA.                                                \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNFKLIFLVALVLMAAFLGQTEG.                                               \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRLSTSALVLGAASSAV.                                                     \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNLASVLLLLAACHLSVSVNG.                                                 \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MLGIWTLLPLVLTYVVRLLSKCVNA.                                             \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MYAASILILHLTWAVATIA.                                                   \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MACRSWVLGILLVLVG.                                                      \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLLGFLIVGLSAISA.                                                      \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MAMIPSISKLLFVAICLF.                                                    \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MAVRPGLWPALLGIVLTAWLRGSGA.                                             \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MELDRAVGVLGAATLLLSFLGMAWA.                                             \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MENRKTFSWLKEQMIRSISVSIMIYVITRTSISNA.                                   \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MPGLGRRAQWLCWWWGLLCS.                                                  \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MVWKVAVFLSVALGIGA.                                                     \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MSGLSRPLLLAVGCLAALCVITAA.                                              \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MQIRYFLALSLLPQVVLA.                                                    \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRSAMLFAAVLALSLAWTFG.                                                  \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRRALLLAALLACAPPAFA.                                                   \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MSLSRRQFIQASGLAMCLGALPFAVQA.                                           \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MALWLQAFTLLVLLVLSSPGAQS.                                               \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MELPILKTNAITAILAAVTLCFASS.                                             \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MTAGLCVCVLLAVLCTSCLG.                                                  \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRLLSFIYLVWLALLTGTPQVSA.                                               \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKYFSVLVVLTLILAIVDQSDA.                                                \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKFLVLALCIAAAVA.                                                       \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MGSSGLLSLLVLFVLLANVQG.                                                 \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNLIIYVTIIALTSA.                                                       \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRGKHIFIITALISILMLAA.                                                  \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MPGQISAVAVLFLSLTVILHG.                                                 \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLLILCLLYYTQLVIC.                                                     \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKSLTLLTICAVLSVSLS.                                                    \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLNPSLLTAAGLVSAQLASA.                                                 \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MSTQPTKTSSTKLRIFKWLFIISTLVAIA.                                         \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MYGIEYTTVLTFLISFILLNYILKSLTRMMDFVIYRFLFVIVVLSPLLKA.                    \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MDVALKLLLLAALTLLASA.                                                   \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRLAPLYRNALLLTGLLLSGIAAVQA.                                            \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKQQKRLYARLLTLLFALIFLLPHSAAAA.                                         \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLLKTVPAIVMLAGGMFASLNA.                                               \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLTCVMIVAVLFLTAWTVVTA.                                                \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MFFWLMCYLVDVWLISA.                                                     \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MMSKLGVLLTICLLLFPLTVLP.                                                \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MAAAIPRAASLSPLFPLLFLLSAPQDSSG.                                         \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MWPAPCSVGRLLIFFMCSSSGYVVQG.                                            \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKTLLLLAFFVGVTCG.                                                      \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MNTVRVTFLLVFVLAVSLGRA.                                                 \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKLSKLLQLAVFSSLVTS.                                                    \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MTRMTRHLALWMLLSLAILASQSAMA.                                            \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MPLLFLWFFLTSTSLVSA.                                                    \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MVRSMRSRVAARAVAWALAVMPLAGAAGLTMAASPAAVA.                               \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKPKSKVAESTAASCFLVMSLLCSCIIG.                                          \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MRLVVCLVFLASFALVCQG.                                                   \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MELGGPGAPPPPLLPPLLLLLGAGFLPASSP.                                       \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MGTPRGLRNAGSSSSACRFLAAFAVLLALPTLTAG.                                   \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKVLWAALLVAFLAGCQG.                                                    \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MCLPSCLLSIWVLFMAAQSLG.                                                 \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MTVLNRLHVCSLLAVSSLGMLPVGVFA.                                           \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKKWLVTIAALWLAG.                                                       \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MSGTILENLSGRKLSILVASLLLCQVFCFLLGGLY.                                   \n",
      "\n",
      "['M', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n",
      "MKKLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLA.\n",
      "$MKFFTVLLFVSLAATSLAL.                                                   \n",
      "\n",
      "['M', 'K', 'K', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'A', '.']\n"
     ]
    }
   ],
   "source": [
    "# See how well it does on first batch_size test sequences\n",
    "file = h5py.File('../data/test_tokens.hdf5')\n",
    "training_data = SignalTranslator.generator_from_h5(file, batch_size, shuffle=False, use_cuda=True)\n",
    "src, tgt = next(training_data) # src is prot sequence, tgt is signal pep\n",
    "file.close()\n",
    "decoded, all_hyp, all_scores, enc_outputs, dec_outputs, enc_slf_attns, dec_slf_attns, dec_enc_attn = clf.translate_batch(src, 1) # predict signal pep from src (prot seq)\n",
    "\n",
    "for tg, dec in zip(tgt[0], decoded):\n",
    "    print(dec) # model's predictions\n",
    "    print(ctable.decode(tg.data.cpu().numpy())[:]) # tgt (actual signal peptide of src)\n",
    "    print()\n",
    "    \n",
    "    tgt_sent = list(dec) # for each word --> for each amino acid\n",
    "    print(tgt_sent)\n",
    "#     for layer in range(1, 6, 2):\n",
    "#         fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "#         print(\"Encoder Layer\", layer+1)\n",
    "#         for h in range(4):\n",
    "#             draw(enc_slf_attns, \n",
    "#                 src, src if h ==0 else [], ax=axs[h]) # sent represents src, string\n",
    "\n",
    "#     for layer in range(1, 6, 2):\n",
    "#         fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "#         print(\"Decoder Self Layer\", layer+1)\n",
    "#         for h in range(4):\n",
    "#             draw(dec_slf_attns, \n",
    "#                 tgt_sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
    "        \n",
    "#         print(\"Decoder Src Layer\", layer+1)\n",
    "#         fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
    "#         for h in range(4):\n",
    "#             draw(dec_enc_attn, \n",
    "#                 sent, tgt_sent if h ==0 else [], ax=axs[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
