{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATED SPLITS WITH SPECIES: Preprocess uniprot data (SPs that are only experimentally verified and verified by sequence analysis) and split into train/val/test with tokens for the species.\n",
    "\n",
    "First, go through and split the sequences into the signal peptide and the remainder of the sequence. \n",
    "Discard sequences where the signal peptide does not start at the first position. Then, discard sequences\n",
    "where the signal peptide is not between 10 and 70 amino acids, inclusive. Also discard sequences where \n",
    "the remaining sequence is not strictly longer than the signal peptide. \n",
    "\n",
    "In one training dataset, keep the first 100 amino acids of the mature protein. In another training dataset, only keep the first 95, 100, and 105 amino acids of the mature protein in the training dataset to vary the length of the protein sequences. This way, we get \"more\" training data if for each one.\n",
    "\n",
    "Remove examples where the SP is the same and the protein sequences are > 0.5 the same.\n",
    "\n",
    "For each example, also save the organism. All organisms with fewer than 5 examples get lumped together as token 0: 'AAUnknown' There are a total of 754 species tokens. \n",
    "\n",
    "There are a total of 32263 examples. \n",
    "\n",
    "Finally, shuffle the signal peptide/mature protein pairs and set aside 20% each as test and validation sets. The split is 19359/6452/6452. \n",
    "\n",
    "Minimal SP Length: 10 AA\n",
    "Maximal SP Length: 70 AA\n",
    " \n",
    "Defaults from SignalP http://www.cbs.dtu.dk/services/SignalP/instructions.php#limits\n",
    " \n",
    "Minimal Protein Length: Longer than Signal Peptide\n",
    "Maximal Protein Length: truncated to 70 -> according the SignalPâ€™s SI (below)\n",
    "https://images.nature.com/full/nature-assets/nmeth/journal/v8/n10/extref/nmeth.1701-S1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creates test batch of protein sequences from Zach's excel \"initial_enzymes_1\" so we can see the attention model's predictions on Zach's protein sequences. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import csv\n",
    "\n",
    "from Bio import pairwise2 as pw2\n",
    "from tools import CharacterTable\n",
    "import h5py \n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in prot sequences from Zach's excel\n",
    "df = pd.read_excel('../data/initial_enzymes_1.xlsx', sheet_name=1)\n",
    "pr_c = df['Protein -met -sigp'].values\n",
    "len(pr_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# Remove exact duplicates\n",
    "pr_c = list(set(pr_c))\n",
    "print(len(pr_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(a=1)\n",
    "random.shuffle(pr_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure prot seq length of test are 100 aa\n",
    "# dataset where training has prot seqs of length 100\n",
    "test = [pr[:100] for pr in pr_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump data where test set has prot seqs of length 100\n",
    "with open('../data/gen_test.pkl', 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ' .$ACDEFGHIKLMNPQRSTUVWXYZ'\n",
    "max_len_in = 107 # max length of prot seq (105 aa) + 2 for tokens\n",
    "max_len_out = 72\n",
    "n_chars = len(alphabet)\n",
    "ctable = CharacterTable(alphabet)\n",
    "\n",
    "def encode(seqs, max_len, ctable):\n",
    "    if ctable.one_hot:\n",
    "        X = np.zeros((len(seqs), max_len, n_chars))\n",
    "    else:\n",
    "        X = np.zeros((len(seqs), max_len))\n",
    "    seqs = ['$' + seq + '.' for seq in seqs]\n",
    "    seqs = [seq + ' ' * ((max_len) - len(seq))for seq in seqs]\n",
    "    for i, seq in enumerate(seqs):\n",
    "        X[i] = ctable.encode(seq, max_len)\n",
    "    return X\n",
    "\n",
    "def to_h5py(seqs, fname, ctable):\n",
    "    chunksize = 500\n",
    "    with h5py.File('../data' + fname + '.hdf5', 'w') as f:\n",
    "        if ctable.one_hot:\n",
    "            print('true')\n",
    "            X = f.create_dataset('X', (len(seqs), max_len_in, n_chars))\n",
    "        else:\n",
    "            X = f.create_dataset('X', (len(seqs), max_len_in))          \n",
    "        for i in range(0, len(seqs), chunksize):\n",
    "            X[i:i + chunksize, :] = encode([seq for seq in seqs[i:i+chunksize]], max_len_in, ctable)\n",
    "        left = len(seqs) % chunksize\n",
    "        if left > 0:\n",
    "            X[-left:, :] = encode([seq for seq in seqs[-left:]], max_len_in, ctable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctable = CharacterTable(alphabet, one_hot=False)\n",
    "to_h5py(test, 'gen_test_tokens_zw2', ctable)\n",
    "# to_h5py(test, 'gen_test_tokens_z', ctable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$ATSRANDAPIVLLHGFTGWGREEMFGFKYWGGVRGDIEQWLNDNGYRTYTLAVGPLSSNWDRACEAYAQLVGGTVDYGAAHAAKHGHARFGRTYPGLLPE.     '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5py.File('../data/gen_test_tokens_z.hdf5', 'r') as f:\n",
    "    X = np.array(f['X'][:10])\n",
    "\n",
    "ctable.decode(X[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = [('MRLSTAQLIAIAYYMLSIGATVPQVDG', 'QGETEEALIQKRSYDYYQEPCDDYPQQQQQQEPCDYPQQQQQEEPCDYPQQQPQEPCDYPQQPQEPCDYPQQPQEPCDYPQQPQEPCDNPPQPDV', 121), ('MLTPRVLRALGWTGLFFLLLSPSNVLG', 'ASLSRDLETPPFLSFDPSNISINGAPLTEVPHAPSTESVSTNSESTNEHTITETTGKNAYIHNNASTDKQNANDTHKTPNILCDTEEVFVFLNET', 260)]\n",
    "leng1 = 0\n",
    "leng2 = 0\n",
    "lst = []\n",
    "\n",
    "for t in train:\n",
    "    si, pr, sp = t\n",
    "    leng1 = len(pr) - 10\n",
    "    leng2 = len(pr) - 5\n",
    "    lst.append(pr[:leng1])\n",
    "    lst.append(pr[:leng2])\n",
    "    lst.append(pr)\n",
    "\n",
    "print(len(lst))\n",
    "list(set(lst))\n",
    "print(len(lst))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
