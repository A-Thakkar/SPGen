{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from transformer import Models\n",
    "from transformer import Beam\n",
    "from transformer import Translator\n",
    "from transformer.Optim import ScheduledOptim\n",
    "\n",
    "from tools import CharacterTable\n",
    "from translator import SignalTranslator\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "with open('../outputs/ctable_token.pkl', 'rb') as f:\n",
    "    ctable = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/gen_test.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "len(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for tokenizing new inputs\n",
    "alphabet = ' .$ACDEFGHIKLMNPQRSTUVWXYZ'\n",
    "max_len_in = 107 # max length of prot seq (105 aa) + 2 for tokens\n",
    "max_len_out = 72\n",
    "n_chars = len(alphabet)\n",
    "\n",
    "with open('../data/ctable_copies/ctable_token_master.pkl', 'rb') as f:\n",
    "    ctable = pickle.load(f)\n",
    "\n",
    "def encode(seqs, max_len, ctable):\n",
    "    if ctable.one_hot:\n",
    "        X = np.zeros((len(seqs), max_len, n_chars))\n",
    "    else:\n",
    "        X = np.zeros((len(seqs), max_len))\n",
    "    seqs = ['$' + seq + '.' for seq in seqs]\n",
    "    seqs = [seq + ' ' * ((max_len) - len(seq))for seq in seqs]\n",
    "    for i, seq in enumerate(seqs):\n",
    "        X[i] = ctable.encode(seq, max_len)\n",
    "    return X\n",
    "\n",
    "def to_h5py(seqs, fname, ctable):\n",
    "    chunksize = 500\n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        if ctable.one_hot:\n",
    "            print('true')\n",
    "            X = f.create_dataset('X', (len(seqs), max_len_in, n_chars))\n",
    "        else:\n",
    "            X = f.create_dataset('X', (len(seqs), max_len_in))          \n",
    "        for i in range(0, len(seqs), chunksize):\n",
    "            X[i:i + chunksize, :] = encode([seq for seq in seqs[i:i+chunksize]], max_len_in, ctable)\n",
    "        left = len(seqs) % chunksize\n",
    "        if left > 0:\n",
    "            X[-left:, :] = encode([seq for seq in seqs[-left:]], max_len_in, ctable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample input, convert to h5py file for generator\n",
    "df = pd.read_excel('../data/example_test_input.xlsx')\n",
    "test_seqs = df['protein_sequence'].values\n",
    "test_seqs = [s[:100] for s in test_seqs]\n",
    "test_filename = ('../data/example_test_tokens.hdf5')\n",
    "to_h5py(test_seqs, test_filename, ctable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cuda=True, d_inner_hid=1100, d_k=64, d_model=550, d_v=64, d_word_vec=550, dropout=0.1, embs_share_weight=True, max_token_seq_len=107, n_head=5, n_layers=6, proj_share_weight=True, src_vocab_size=27, tgt_vocab_size=27) Namespace(beam_size=1, ctable=<tools.CharacterTable object at 0x7ff7a23905c0>, max_trans_length=72, n_best=1) Namespace(d_model=None, decay_power=-0.03, lr_max=0.0001, n_warmup_steps=12500, optim=<class 'torch.optim.adam.Adam'>)\n",
      "position_encoding\n",
      "position_encoding\n",
      "Initiated Transformer with 27403200 parameters.\n"
     ]
    }
   ],
   "source": [
    "# Load a Model Checkpoint\n",
    "chkpt_name = 'SIM99_550_12500_64_6_5_0.1_64_100_0.0001_-0.03_99'\n",
    "chkpt = \"../outputs/models/model_checkpoints/\" + chkpt_name + \".chkpt\"\n",
    "clf = SignalTranslator.load_model(chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = self.forward(*input, **kwargs)\n",
      "/home/ubuntu/signal_peptide/code/translator.py:376: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.model.prob_projection(dec_output)\n"
     ]
    }
   ],
   "source": [
    "# test_gen_data = []\n",
    "# Generate SPs for Proteins\n",
    "file = h5py.File(test_filename)\n",
    "training_data = SignalTranslator.generator_from_h5_noy(file, 64, shuffle=False, use_cuda=True)\n",
    "src = next(training_data) # src is prot sequence, tgt is signal pep\n",
    "file.close()\n",
    "clf_outputs  = clf.translate_batch(src, 5)\n",
    "decoded, all_hyp, all_scores, enc_outputs, dec_outputs,  \\\n",
    "    enc_slf_attns, dec_slf_attns, dec_enc_attn = clf_outputs\n",
    "\n",
    "for src, dec in zip(src[0], decoded):\n",
    "#     print(ctable.decode(src.data.cpu().numpy())[:]) # prot sequence from Zach's excel\n",
    "#     print(dec) # model's predictions\n",
    "#     print()\n",
    "    \n",
    "    input_seq = ctable.decode(src.data.cpu().numpy())[:]\n",
    "    output_seq = dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in Model criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer.Constants as Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(vocab_size):\n",
    "    ''' With PAD token zero weight '''\n",
    "    weight = torch.ones(vocab_size)\n",
    "    weight[Constants.PAD] = 0\n",
    "    return nn.CrossEntropyLoss(weight, size_average=False)\n",
    "\n",
    "crit = get_criterion(27)\n",
    "\n",
    "if clf.cuda:\n",
    "    crit = crit.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy function\n",
    "def num_matches(tgt, dec):\n",
    "    ''' Return number of matches between true target and decoded sequence\n",
    "    '''\n",
    "    true = ctable.decode(tgt.data.cpu().numpy())[:].strip()\n",
    "    true = true[1:]\n",
    "    gen = dec.strip()  \n",
    "    \n",
    "    diff = len(true) - len(gen)\n",
    "    if diff > 0:\n",
    "        pad = '_'*diff\n",
    "        gen = gen + pad\n",
    "\n",
    "    matches = 0\n",
    "    for i, aa in enumerate(true):\n",
    "        if gen[i]==aa:\n",
    "            matches += 1\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = self.forward(*input, **kwargs)\n",
      "/home/ubuntu/signal_peptide/code/translator.py:376: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.model.prob_projection(dec_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy mean/std: 0.34501638552782715 0.3010739483939744\n",
      "Log likelihood mean/std: -3.0666218 1.9270155\n"
     ]
    }
   ],
   "source": [
    "# Get validation files\n",
    "# val_file = h5py.File('../data/validate_tokens.hdf5')\n",
    "val_file = h5py.File('../data/filtered_datasets/validate_tokens_99.hdf5')\n",
    "val_dataloader = SignalTranslator.generator_from_h5(val_file, batch_size=1, shuffle=False, use_cuda=True)\n",
    "\n",
    "clf.model.eval(); # Evaluation Mode\n",
    "\n",
    "log_lks = []\n",
    "accs = []\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    src, tgt = batch\n",
    "    trans_outs = clf.translate_batch(src, 5) # predict signal pep from src (prot seq)\n",
    "    decoded, all_hyp, all_scores, enc_outputs, dec_outputs, \\\n",
    "        enc_slf_attns, dec_slf_attns, dec_enc_attn = trans_outs\n",
    "\n",
    "    scores = [i.cpu().numpy()[0] for i in all_scores]\n",
    "    log_lks += scores\n",
    "\n",
    "    for tgt, dec in zip(tgt[0], decoded):\n",
    "        matches = num_matches(tgt,dec)\n",
    "        accs.append(matches/len(tgt[tgt!=0]))\n",
    "\n",
    "print('accuracy mean/std:', np.average(accs), np.std(accs))\n",
    "print('Log likelihood mean/std:', np.average(log_lks), np.std(log_lks))    \n",
    "# print(len(log_lks), np.average(log_lks), np.std(log_lks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy mean/std: 0.34501638552782715 0.3010739483939744\n",
      "Log likelihood mean/std: -3.0666218 1.9270155\n"
     ]
    }
   ],
   "source": [
    "print('accuracy mean/std:', np.average(accs), np.std(accs))\n",
    "print('Log likelihood mean/std:', np.average(log_lks), np.std(log_lks)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
